<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MAT9004复习总(3)]]></title>
    <url>%2F2019%2F06%2F08%2FMAT9004%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%933%2F</url>
    <content type="text"><![CDATA[MAT9004复习总结(3) 这部分主要总结记录一些关于线性代数相关的基础知识点. Important Proporty The line interval join points u and v contains exactly the points corresponding to vectors of the form (\(0 \leq \alpha \leq 1\)) : \[\alpha u + (1-\alpha)v\] Linear independence \(v_1,...,v_n\) are linearly dependent if one of the \(v_j\) is a linear combination of the other vectors \(v_1,...,v_{j-1}, v_{j+1}, ...,v_n\). If not linearly dependent, they are linearly independent. The Dot Product The dot product of two vectors is : \[v·w = v_1w_1 + v_2w_2 + ... + v_dw_d\] The dot product is also called the scalar product or the inner product, and another notation for the dot product is \(&lt;v,w&gt;\) The Euclidean Norm The (Euclidean) norm of a vector is : \[||v|| = \sqrt {v_1^2+v_2^2+...+v_d^2} = \sqrt {v·v}\] For vectors in dimensions 2 and 3, Pythagoras' theorem tells us $||v|| is equal to the distance from the original Cartesian coordinates, to the point representing \(v\) (The length of \(v\)). Orthogonal Vectors (正交向量) Vectors \(v\) and \(w\) are called orthogonal if : \[v·w = 0\] Matrix Matrix Multiplication Let \(A= \left( \begin{matrix} a_{11} &amp; a_{12} \\ a_{21} &amp; a_{22} \end{matrix} \right)\), and \(B= \left( \begin{matrix} b_{11} &amp; b_{12} \\ b_{21} &amp; b_{22} \end{matrix} \right)\), then : \[AB = \left( \begin{matrix} a_{11}b_{11} + a_{12}b_{21} &amp; a_{11}b_{12} + a_{12}b_{22} \\ a_{21}b_{11} + a_{22}b_{21} &amp; a_{21}b_{12} + a_{12}b_{22} \end{matrix} \right)\] We can only multiply an \(m\) x \(n\) by an \(n\) x \(r\) matrix, and the result is \(m\) x \(r\). Rules for Add/Mul \(A(BC) = (AB)C\) \((k+j)A = kA+jA\) \((kA)B = A(kB)\) \(A(B+D) = AB+AD\) and \((E+F)G = EG+FG\) Gaussian Elimination Gaussian elimination makes use of certain operations we can apply to the matrix equation that do not change the set of solutions of the linear systems. If we have : \[\left( \begin{matrix} 0 &amp; 2 &amp; 1 \\ 2 &amp; -2 &amp; 1 \\ 2 &amp;2&amp;-2 \end{matrix} \right) \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix}1 \\ 5 \\ -4 \end{matrix} \right)\] Swap two rows : \[\left( \begin{matrix} 2 &amp; -2 &amp; 1 \\ 0 &amp; 2 &amp; 1 \\ 2 &amp;2&amp;-2 \end{matrix} \right) \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix}5 \\ 1 \\ -4 \end{matrix} \right)\] Multiply a row by a non-zero number : \[\left( \begin{matrix} 1 &amp; -1 &amp; 0.5 \\ 0 &amp; 2 &amp; 1 \\ 2 &amp;2&amp;-2 \end{matrix} \right) \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix}2.5 \\ 1 \\ -4 \end{matrix} \right)\] Add a multiple of one row to another row : Here we subtract 2 times the first row from the third : \[\left( \begin{matrix} 1 &amp; -1 &amp; 0.5 \\ 0 &amp; 2 &amp; 1 \\ 0 &amp;4&amp;-3 \end{matrix} \right) \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix}2.5 \\ 1 \\ -9 \end{matrix} \right)\] Basic Strategy of Gaussian Elimination The idea of Gaussian elimination is to use the operations described above, one after another, to transform the linear system into upper triangular form : \[\left( \begin{matrix} * &amp; * &amp; * \\ 0 &amp; * &amp; * \\ 0&amp;0&amp;* \end{matrix} \right) \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix}*\\ *\\ *\end{matrix} \right)\] Non-square \[\left( \begin{matrix} 1 &amp; 2 \\ 0 &amp; 0 \\ 0&amp;0\end{matrix} \right) \left( \begin{matrix} x \\ y \\ z \end{matrix} \right) = \left( \begin{matrix}1\\ 0 \\ 0 \end{matrix} \right)\] The only remaining equation is \(x+2y=1\), which gives \(x=1-2y\), so the solutions are \((x,y) = \{(1-2y, y), y \in R\}\) Identity Matrices An identity matrix is an \(n\) x \(n\) matrix \(I\) with \((I)_{ii} = 1\) and \((I)_{ij} = 0\) for \(i \neq j\), like : \[\left( \begin{matrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; 1 \end{matrix} \right) \] The multiplication with an identity matrix has no effect, i.e. \(AI=IA=A\) \(I\) behaves like the real number \(1\) The \(n\) x \(n\) identity matrix is often denoted by \(I_n\) Matrix Inverse A square matrix \(A\) is called invertible if there is a square matrix \(such\) that \(BA=I\). The matrix \(B\) is called the inverse matrix of \(A\) and is denoted by \(A^{-1}\) Determinants The determinate of a square matrix \(A\) is a real number \(det(A)\) with the following properties : \(det(AB) = det(A)det(B)\) for square matrices \(det(I) = 1\) \(det(A) \neq 0\) if and only if \(A\) is invertible For 2x2 matrix the following formula holds for \(det(A)\) : \[det\left( \begin{matrix} a &amp; b \\ c &amp; d\end{matrix} \right) = ad - bc\] Finding Inverse Let \(A = \left( \begin{matrix} a &amp; b \\ c&amp;d \end{matrix} \right)\), \(A\) is invertible if, and only if, \(det(A) \neq 0\), in which case : \[A^{-1} = {1\over det(A)}\left( \begin{matrix} d &amp; -b \\ -c &amp; a \end{matrix} \right)\] If \(A\) is invertible then the linear system \(Ax=b\) has exactly one solution \(x=A^{-1}b\). Eigenvalues An eigenvalue of \(A\) is any real number \(\lambda\) such that \(Ax=\lambda x\) for some non-zero vector \(x\). Finding Eigenvalues \[Ax=\lambda x\] \[Ax=\lambda I x\] \[Ax-\lambda I x=0\] \[(A-\lambda I) x=0\] This equation has multiple solutions only and only if the matrix \(A-\lambda I\) has no inverse, which means \(det(A-\lambda I)=0\). The characteristic equation of a square matrix \(A\) is \(det(A-\lambda I)=0\) Here \(det(A-\lambda I)=0\) is just a polynomial in \(x\), and it's called characteristic polynomial of \(A\) Eigenvectors An eigenvector of \(A\) is any non-zero vector \(x\) which satisfies \(Ax=\lambda x\) for some real number \(\lambda\). The zero vector is not an eigenvector. Diagonal Matrices A matrix \(D\) is called diagonal if \((D)_{ij}=0\) for all \(i \neq j\), like : \[\left( \begin{matrix} a&amp;0&amp;0 \\ 0&amp;b&amp;0 \\ 0&amp;0&amp;c \end{matrix} \right)\] Diagonalisable Matrices A square matrix \(A\) is called diagonalisable if there is an invertible matrix \(P\) and a diagonal matrix \(D\) such that : \[A=PDP^{-1}\] \[A^n = PD^nP^{-1}\] Eigen Decomposition If \(D\) is the diagonal matrix with \((D)_{ii}=\lambda _i\) and \((D)_{ij}=0\) for \(i \neq j\). And if \(v_i\) be an eigenvector corresponding to the eigenvalue \(\lambda _i\), define \(P=(v_1,...,v_n)\). Then \(A=PDP^{-1}\) PageRank]]></content>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAT9004复习总结(2)]]></title>
    <url>%2F2019%2F06%2F07%2FMAT9004%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%932%2F</url>
    <content type="text"><![CDATA[MAT9004复习总结(2) 这部分记录一些很简单的函数相关值知识，基本高中范围. Concave Function A function is concave if, for any two points in its plot, the straight line between both points is entirely below (or touching) the plot of the function. Convex Function A function is convex if, for any two points in its plot, the straight line between both points is entirely above (or touching) the plot of the function. Bijection A function \(f : X → Y\) is called : injective (or one-to-one) if for all distinct \(x1, x2 ∈ X\) and \(f(x1) != f(x2)\) surjective if \(Y = f (X)\), that is if for every \(y ∈ Y\) there is an \(x ∈ X\) with \(f (x) = y\) bijective if it is both injective and surjective Log-Log Plot The log-log plot of a data set \((x_1, y_1), . . . ,(x_n, y_n)\) is the plot of the data \((ln(x_1), ln(y_1)), . . .(ln(x_n), ln(y_n))\) If \((x_1, y_1), . . . ,(x_n, y_n)\) are points of the graph of a power-law function, then \((ln(x_1), ln(y_1)), . . . ,(ln(x_n), ln(y_n))\) are points of the graph of a linear function with : slope equal to the exponent of the power-law function y-intercept equal to ln(b), if the original function was \(f (x) = bx^{−a}\) Derivertive Rules If \(f (x) = f_1(f_2(x))\) then \(f&#39;(x) = f&#39;_2 (x)f&#39;_1(f&#39;_2(x)\) If \(g(x) = g_1(x)g_2(x)\) then \(g&#39;(x) = g&#39;_1(x)g_2(x) + g_1(x)g&#39;_2 (x)\) If \(h_1(x) = x^b\) then \(h&#39;_1 (x) = bx^{b−1}\) If \(h_2(x) = a^x\) then \(h&#39;_2 (x) = ln(a)a^x\) If \(h3(x) = log_a(x)\) then \(h&#39;_3(x) = {1 \over ln(a)x}\) Increasing/Decreasing of Function For an arbitrary function f : On any interval where \(f&#39;(x)\) is positive, \(f\) increases On any interval where \(f&#39;(x)\) is negative, \(f\) decreases Local Maxima/Minima A local maximum of f is a stationary point where f 0 changes from positive to negative (as x moves left to right) A local minimum of f is a stationary point where f 0 changes from negative to positive Sufficient Conditions for Judging If a is a stationary point of \(f\) and \(f&#39;&#39;(a)\) exists then : \(f\) has a local minimum at \(x = a\) if \(f&#39;&#39;(a) &gt; 0\) \(f\) has a local maximum at \(x = a\) if \(f&#39;&#39;(a) &lt; 0\) \(f&#39;&#39;(a) = 0\) gives no conclusion Antiderivatives A function \(F\) is an antiderivative of f if \(F&#39; = f\) Some basic antiderivatives If \(f (x) = x^a\) where \(a \neq −1\); \(F(x) = {1\over a+1} x^{a+1}\) If \(f (x) = x^{−1}\) ; \(F(x) = ln(x)\) If \(f (x) = e^{ax}\) where \(a \neq 0\); \(F(x) = {1\over a} e^{ax}\) Calculus If \(F\) is an antiderivative of \(f\) then : \[\int_a^b f(x) dx = F(b) - F(a)\] And \(F(x)+c\) is the indefinite integral of \(f\) Linearity If \(f\) and \(g\) are functions then : \[\int_a^b f(x)+g(x) dx = \int_a^b f(x)dx + \int_a^b g(x)dx\] If \(f\) is a function and \(c\) is a constant then : \[\int_a^b cf(x)dx = c\int_a^b f(x) dx\] Another Property If \(a,b,c\) are real numbers with \(a&lt;b&lt;c\) then : \[\int_a^c f(x) dx = \int_a^b f(x) dx + \int_b^c f(x) dx\]]]></content>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Summary]]></title>
    <url>%2F2019%2F06%2F01%2FPython-Summary%2F</url>
    <content type="text"><![CDATA[Python Summary A brief summary of Python, including some basic foundations. immutable and mutable variable There are two kinds of variables in Python which are immutable and mutable variable. As for immutable variables, some common type like int, float, string, tuple and set. And in terms of mutable variables, it includes dict and list. We can not change the elements in immutable variables : 123sample_sentence = "This is a sentence"sample_sentence[2] = '5'&gt;&gt;&gt; TypeError: 'str' object does not support item assignment However, we can modify the mutable variables : 1234sample_list = ['This', 'is', 'a', 'sentence']sample_list[2] = 'A'print(' '.join(sample_list))&gt;&gt;&gt; This is A sentence According to this feature of the two above kind of vairables, we can use them in the parameters in functions. There's no return statement in the function, but the original list has been modified since the list type is mutable, and the reference is delivered in Python : 1234567def test_func(sample): sample[2] = 'A'sample_list = ['This', 'is', 'a', 'sentence']test_func(sample_list)print(' '.join(sample_list))&gt;&gt;&gt; This is A sentence As for the immutable variables, the situation is not similar with the above function. Since the type string is immutable, Python will create a new variable to store the parameters and copy the value of the original variables : 12345678def test_func(sample): sample = list(sample) sample[2] = 'A'sample_sentence = 'This is s sentence'test_func(sample_sentence)print(sample_sentence)&gt;&gt;&gt; This is a sentence Collective Data Types Set A data type for representing a collection of unique, unordered items. Creating set An empty set: a_set = set() A set with a number of items: a_set = {"one", 2} Build a set from a list: a_set = set([1, 2, 2, 3]) Adding new items to a set Syntax: a_set.add('c') Removing items from a set remove(): accept one argument indicating the item to be removed; raise KeyError if the item does not exist discard(): similar to remove(); does not raise KeyError if item does not exist pop(): select an arbitrary item to remove and return it clear(): remove all the items from a set in place Set operations Union: a_set.union(b_set), a_set | b_set Intersection: a_set.intersection(b_set), a_set &amp; b_set Difference: a_set.difference(b_set), a_set - b_set Symmetric difference: a_set.symmetric_difference (b_set), a_set ^ b_set Dictionary A mapping data type that associates a key with a value, keys must be immutable types; values can be of any data type, 3ach data item is represented as key:value. Creating dictionary An empty dictionary: a_dict = {} or a_dict = dict() A dictionary with a number of items: a_dict = {'one':1, 'two':2} Build a dictionary from a list of tuples: a_dict = dict([('a',1), ('b',1)]) Adding new items to a dictionary Syntax: a_dict[new_key] = new_value If new_key presents in the dictionary, the existing value associated to this key is updated to new_value Removing items from a dictionary Syntax: del a_dict[a_key] Checking for a key in a dictionary Syntax: a_key in a_dict or a_key not in a_dict File Operation The open(file, mode) function will open the specific file in the specific mode : Open modes for file writing : open(file_handle, 'w'): overwrite the existing content of the output file with the new content open(file_handle, 'a'): append the new content at the end of the output file Writing lines to a file : * file_handle.write(the_line): write one line at a time to the file Reading line by line : 12345678910with open(file, 'a') as file_handle: lines = file_handle.readlines() for line in lines: print(line) with open(file, 'a') as file_handle: line = file_handle.readline() while line: print(line) line = file_handle.readline() Simple Stack 12345678910111213141516171819202122232425262728293031class Stack: def __init__(self): self.the_stack = [] self.count = 0 self.top = -1 def __len__(self): return self.count def is_empty(self): return len(self) == 0 def push(self, item): self.the_stack.append(item) self.count += 1 self.top += 1 def pop(self): assert not self.is_empty(), "Can not pop from an empty stack" item = self.the_stack[self.top] del self.the_stack[self.top] self.count -= 1 self.top -= 1 return item def peek(self): assert not self.is_empty(), "Can not peek from an empty stack" item = self.the_stack[self.top] return item Simple Queue 1234567891011121314151617181920212223242526class Queue: def __init__(self): self.the_queue = [] self.count = 0 self.front = 0 self.rear = -1 def __len__(self): return self.count def is_empty(self): return len(self) == 0 def append(self, item): self.the_queue.append(item) self.count += 1 self.rear += 1 def serve(self): assert not self.is_empty(), "Can not serve from an empty queue" item = self.the_queue[self.front] del self.the_queue[self.front] self.count -= 1 self.front += 1 return item Queue with capacity : 123456789101112131415161718192021222324252627282930class Queue: def __init__(self, size): self.the_queue = [0] * size self.count = 0 self.front = 0 self.rear = len * (self.the_queue) - 1 def __len__(self): return self.count def is_empty(self): return len(self) == 0 def is_full(self): return len(self) == len(self.the_queue) def append(self, item): assert not self.is_full(), "Can not append to a full queue" self.rear += (self.rear + 1) % len(self.the_queue) self.the_queue[self.rear] = item self.count += 1 def serve(self): assert not self.is_empty(), "Can not serve an empty queue" item = self.the_queue[self.front] del self.the_queue[self.front] self.front = (self.front + 1) % len(self.the_queue) self.count -= 1 return item Random Module random(): return a random floating point number in the range [0.0, 1.0) randint(a, b): return a random integer in the range [a, b] Simple Search Algorithms Linear Searching 12345def linear(target): for x in list_1: if x == target: return True return False Best case: 1 operation Worst case: n operations Binary Seacrching Time complexity: \(O(logn)\) 12345678910111213def binary(target): list_2.sort() low = 0 high = len(list_2) - 1 while low &lt;= high: mid = (low + high) // 2 if list_2[mid] == target: return True elif list_2[mid] &lt; target: high = mid - 1 else: low = mid + 1 return False Simple Sorting Algorithms Bubble Sort Time complexity: \(O(n^2)\) 12345678def bubble_sort(the_list): for i in range(len(the_list) - 1): for j in range(len(the_list) - i - 1): if the_list[j] &gt; the_list[j+1]: temp = the_list[j] the_list[j] = the_list[j+1] the_list[j+1] = temp return the_list Selection Sort Time complexity: \(O(n^2)\) 123456789101112def selection_sort(the_list): for i in range(len(the_list) - 1): smallest = i for j in range(i, len(the_list)): if the_list[j] &lt; the_list[smallest]: smallest = j temp = the_list[i] the_list[i] = the_list[smallest] the_list[smallest] = temp return the_list Insertion Sort Time complexity: \(O(n^2)\) 12345678910def insertion_sort(the_list): for i in range(1, len(the_list)): current = the_list[i] pos = i while pos &gt; 0 and the_list[pos-1] &gt; current: the_list[pos] = the_list[pos-1] pos -= 1 the_list[pos] = current return the_list Testing 12345678910111213141516171819202122232425262728293031323334353637383940414243def calculate_GPA(grade_list): total_sum = 0.0 gpa = 0.0 for grade in grade_list: if grade.upper() == "A": total_sum += 4.0 elif grade.upper() == "B": total_sum += 3.0 elif grade.upper() == "C": total_sum += 2.0 elif grade.upper() == "D": total_sum += 1.0 elif grade.upper() == "F": total_sum += 0.0 else: return -1 gpa = float(total_sum / len(grade_list)) return gpaimport unittestclass TestForGPA(unittest.TestCase): def test_calculate(self): self.assertEqual(calculate_GPA(['A','A','A']), 3.0) test = TestForGPA()suite = unittest.TestLoader().loadTestsFromModule(test)unittest.TextTestRunner().run(suite)[out]F======================================================================FAIL: test_calculate (__main__.TestForGPA)----------------------------------------------------------------------Traceback (most recent call last): File "&lt;ipython-input-32-0f3c215f8395&gt;", line 7, in test_calculate self.assertEqual(calculate_GPA(['A','A','A']), 3.0)AssertionError: 4.0 != 3.0----------------------------------------------------------------------Ran 1 test in 0.001sFAILED (failures=1) Exception Handling 123456789try: input_handle = open('simple_file.txt','r')except FileNotFoundError: print('File not found')else: passfinally: import sys sys.exit() Recursion Recursive Binary Search 12345678910111213def rec_binary_search(the_list, target): if len(the_list) == 0: return False mid = len(the_list) // 2 if the_list[mid] == target: return True elif the_list[mid] &lt; target: smaller_list = the_list[:mid] rec_binary_search(smaller_list, target) else: smaller_list = the_list[mid+1:] rec_binary_search(smaller_list, target) Merge Sort 12345678910111213141516171819202122232425262728293031323334def merge_sort(the_list): n = len(the_list) if n &gt; 1: mid = n // 2 left = the_list[:mid] right = the_list[mid:] merge_sort(left) merge_sort(right) i = 0 # left list j = 0 # right list k = 0 # main list while i &lt; len(left) and j &lt; len(right): if left[i] &lt;= right[j]: the_list[k] = left[i] i += 1 else: the_list[k] = right[j] j += 1 k += 1 while i &lt; len(left): the_list[k] = left[i] i += 1 k += 1 while j &lt; len(right): the_list[k] = right[j] j += 1 k += 1 print(the_list) Quick Sort 123456789101112131415161718192021222324252627282930313233343536373839def quick_sort(the_list): first = 0 last = len(the_list) - 1 quick_sort_aux(the_list, first, last) def quick_sort_aux(the_list, first, last): if first &lt; last: partition_point = partitioning(the_list, first, last) quick_sort_aux(the_list, first, partition_point - 1) quick_sort_aux(the_list, partition_point + 1, last) def partitioning(the_list, first, last): pivot_value = the_list[first] left_index = first + 1 right_index = last complete = False while not complete: while left_index &lt;= right_index and the_list[left_index] &lt;= pivot_value: left_index += 1 while right_index &gt;= left_index and the_list[right_index] &gt;= pivot_value: right_index -= 1 if right_index &lt; left_index: complete = True else: temp = the_list[left_index] the_list[left_index] = the_list[right_index] the_list[right_index] = temp temp = the_list[first] the_list[first] = the_list[right_index] the_list[right_index] = temp return right_index]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL Summary]]></title>
    <url>%2F2019%2F05%2F20%2FSQL%20Summary%2F</url>
    <content type="text"><![CDATA[SQL Summary Creating Tables 12345678create table unit( unit_code char(7) not null, unit_name varchar2(50) constraint uq_unit_name unique not null, student_id number(7, 0) not null, constraint pk_unit primary key (unit_code) constraint fk_student foreign key (student_id) references student(student_id)); And another way to add constraint: 12alter table unit add (constraint fk_student foreign key (student_id) references student(student_id)); The difference between varchar and varchar2: VARCHAR is reserved by Oracle to support distinction between NULL and empty string in future, as ANSI standard prescribes. VARCHAR2 does not distinguish between a NULL and empty string, and never will. Referential Integrity RESTRICT : Deletion of tuples is NOT ALLOWED for those tuples in the table referred by the FK (the table containing PK) if there is corresponding tuple in the table containing the FK. CASCADE : A deletion of a tuple in the table referred by the FK (the table containing PK) will result in the deletion of the corresponding tuples in the table containing the FK. NULLIFY : A deletion of a tuple in the table referred by the FK (the table containing PK) will result in the update of the corresponding tuples in the table containing the FK to NULL. Using Sequence Oracle supports auto-increment of a numeric PRIMARY KEY. 1234create sequence sno_seq start with 0 increment by 1;insert into student values (sno_seq.nextval, 'Bond', 'James', to_date('01-Jan-1994’, 'DD-MM-YYYY'));insert into enrolment values (sno_seq.currval, ’FIT9132’); Alter Tables Adding columns to the original table : 12345alter table studentadd (stu_address varchar(200), status char(1) default 'C', constraint status_ck check (status in ('G', 'C')) ); Adding referential integrity : 123alter table enrolmentadd (constraint fk_enrolment_student foreign key (stu_nbr) references student (stu_nbr) on delete cascade, constraint fk_enrolment_unit foreign key (unit_code) references unit (unit_code) on delete cascade); Add Rows Use to_char() and to_date() to convert the format between string and date. rollback function can undo the changes. 1insert into student values (112233, 'Wild', 'Wilbur', to_date('01-Jan-1995 18:00:00', 'DD-MM-YYYY HH24:MI:SS')) Select Statement &lt;&gt; means not equal to, this expression can be transplanted to other database platform, != doesn't work in some database version. 123select stu_id, stu_fname, stu_lnamefrom studentwhere stu_fname = 'Dylan'; Range 123select staff_info from staffwhere salary between 1000 and 3000; Which equals to : 123select staff_infofrom staffwhere salary &gt;= 1000 and salary &lt;= 3000; Set Membership To test whether the value of expression equals one of a set of values. 123select city_infofrom citywhere city in ('Melbourne', 'Sydney'); Pattern Match To test whether a string (text) matches a specified pattern. % character represents any sequence of zero or more character. _ character represents any single character. 12345678910111213141516select city_infofrom citywhere city like 'M%';select unit_info fron unitwhere unit_code like 'FIT50__' ``` ### NVLThis function is used to replace a null with a value : ```SQLselect stu_id, nvl(enrol_mark, 0), nvl(enrol_grade, 'WH')from enrolment; Rename Column Use QL Summary Creating Tables 12345678create table unit( unit_code char(7) not null, unit_name varchar2(50) constraint uq_unit_name unique not null, student_id number(7, 0) not null, constraint pk_unit primary key (unit_code) constraint fk_student foreign key (student_id) references student(student_id)); And another word 'as' to rename the column in the selection result : 1234567select stu_id, enrol_mark/10 as new_markfrom enrolment;select stu_id, enrol_mark/10 as "new mark"from enrolment; Sort Query Result Order can be ascending or descending, the default is ascending. Null values can be explicitly placed first/last using nulls last or nulls first command. 123select stu_id, enrol_markfrom enrolmentorder by enrol_mark desc; Distinct The key word "distinct" can be used as part of select clause to remove duplicate rows in the query result : 123select distinct stu_idfrom enrolmentwhere enril_mark is null; Join 12345select s.stu_id, s.stu_lname, u.unit_namefrom unit u join enrolment e on u.unit_code = e.unit_code join student s on e.stu_id = s.stu_idorder by s.stu_nbr, u.unit_name; Add constraint: 12alter table unit add (constraint fk_student foreign key (student_id) references student(student_id)); The difference between varchar and varchar2: VARCHAR is reserved by Oracle to support distinction between NULL and empty string in future, as ANSI standard prescribes. VARCHAR2 does not distinguish between a NULL and empty string, and never will. Referential Integrity RESTRICT : Deletion of tuples is NOT ALLOWED for those tuples in the Statement 123456update enrolmentset mark=85where unit_code = (select unit_code from unit where unit_name = 'Database') and mark = 80; Delete Statement 1234567delete from enrolmentwhere sno = '29394678' and unit_code = (select unit_code from unit where unit_name = 'Database') and semester = '1' and year = '2019'; Transactions Atomicity : all database operations (sql requests) of a transaction must be entirely completed or aborted Consistency : it must take the datebase from one consistent state to another Isolation : it must not interfere with oble referred by the FK (the table containing PK) if there is corresponding tuple in the table containing the FK. CASCADE : A deletion of a tuple in the table referred by the FK (the table containing PK) will result in the deletion of ther concurrent transactions; data used during execution of a transaction cannot be used by a second transaction until the first one is completed Durability : once completed the changes the transaction made to the data are durable, even in the event of system failure Lock Types Shared Lock : multiple processes can simultaneously hold shard locks, to enable them to read without updating : if a transaction \(T_i\) has obtained a shared lock on data item \(Q\), then \(T_i\) can read this item but not write to this item Exclusive Lock : a process that needs to update a record must obtain an exclusive lock. Its application for a lock will not proceed until all current locks are released : if a transaction \(T_i\) has obtained an exclusive lock on data item \(Q\), then \(T_i\) can both read and write to item \(Q\) Deadlock A sample scenario : Transaction 1 has an exclusive lock on data item A, and requests a lock on data item B; Transaction 2 has an exclusive lock on data item B, and requests a lock on data item A. Then deadlock happen. Deadlock prevention : A transaction must acquire all the locks it requires before it updates any record If it cannot acquire a necessory lock, it releases all locks, and tries again later Check Point Any transaction that was running at the time of failure needs to be undone and restarted Any transactions that committed since the last checkpoint need to be redone Group By If a group by clause is used with aggregate function, the database will apply the aggregate function to the different groups defined in the clause rather than all rows. 123456789101112selecrresponding tuples in the table containing the FK.3. NULLIFY : A deletion of a tuple in the table referred by the FK (the table containing PK) will result in the update of the corresponding tuples in the table containing the FK to NULL.### Using SequenceOracle supports auto-increment of a numeric PRIMARY KEY.```SQLcreate sequence sno_seq start with 0 increment by 1;insert into student values (sno_seq.nextval, 'Bond', 'James', to_date('01-Jan-1994’, 'DD-MM-YYYY'));insert into enrolment values (sno_seq.currval, ’FIT9132’); Alter Tables Adding columns to the original table : 12345alter table studentadd (stu_address varchar(200, status char(1) default 'C', constraint status_ck check (status in ('G', 'C')) ); Adding referential integrity : 12345alter table enrolmentadd (constraint fk_enrolment_student foreign key (stu_nbr) references student (stu_nbr) on delete cascade, constraint fk_enrolment_unit foreign key (unit_code) references unit (unit_code, avg(mark)from enrolmentgroup by unit_co) on delete cascade); Having Clause It is u Add Rows **Used to put a condition or conditions on the groups defined by group by clause : 1234select unit_code, avg(mark), count(*)from enrolmentgroup bt unit_codehaving avg(mark) &gt; 50; The where clause is applied to all rows in the table The having clause is applied to the groups defined by the group by caluse The order of operations performed is from, where, group by, having and then order by _char() and to_date() to convert the format between string and date**. rollback function can undo the changes. 1insert into student values (112233, 'Wild', 'Wilbur', to_date('01-Jan-1995 18:00:00', 'DD-MM-YYYY HH24:MI:SS')) Subqueries Simple Example Find all students whose mark is higher than the average mark of all enrolled students : 123select *from enrolmentwhere mark &gt; (select avg(mark) from enrolment); Nested For each unit, find the students who obtained the maximum mark in the unit : 12345select studid, unitcode, markfrom enrolmentwhere (unitcode, mark) in (select unitcode, max(mark) from enrolment group by unitcode); This subquery is independent of the ourter query and is executed only once. Correlated For each unit, find the students who obtained the maximum mark in the unit : 12345select studid, unitcode, markfrom enrolment e1where mark = (select max(mark) from enrolment e2 where e1.unitcode = e2.unitcode); This subquery is related to the outer query and is considered to be evaluated once for each row of the outer query. Inline (Derived Table) For each unit, find the students who obtained the maximum mark in the unit : 123456select studid, e.unitcode, mark as max_markfrom (select unitcode, max(mark) from enrolment group by unitcode) max_table join enrolment e on e.unitcode = max_table.unitcode and e.mark = max_table.max_mark; Triggers Row Level Trigger FOR EACH ROW option : the for each row option determines whether the trigger is a row trigger or a statement trigger. If we specific for each row, the trigger fires once for each row of the table that is affected by the triggering statement. The absence of the for each row option means that the trigger fires only once for each applicable statement, but not separately for each row affected by the statement. Update the item_code when it is modified in the table 'item' : 123456789create or replace trigger item_updateafter update of item_code on itemfor each rowbegin update item_treatment set item_code = :new.item_code where item_code = :old.item_code dbms_output.put_line('Update Successfully')end; Check the validation of last name and first name : 12345678create or replace trigger check_namebefore insert or update on patientfor each rowbegin if :new.patient_fname is null and :new.patient_lname is null then raise_application_error(-20000, 'Empty Name Error'); end if;end; If we want to modify the original table, we need to change the :new value not directly writing to the table, via say an update which would cause a mutating table error : 1234567891011121314create or replace trigger calculate_gradebefore insert or update of enrol_mark on enrolmentfor each rowdeclare final_grade enrolment.enrol_grade%type;begin if :new.enrol_mark &gt;= 70 and :new.enrol_mark &lt; 80 then final_grade := 'D'; elsif :new.enrol_mark &gt;= 60 and :new.enrol_mark &lt; 70 then final_grade := 'C'; end if; :new_enrol_grade := final_grade;end; Statement Level Trigger Executed once for the whole table but will have to check all rows in the table In many cases, it will be inefficient No access to the correlation values :new and :old Views A virtual table derived from one or more base tables Sometimes used as access control to the database Aim : Reduce complexity and enhance security There's no any true data in the view, these data are dynamically generated when the view is referenced For each unit, find the students who obtained the maximum mark in the unit : 123456create or replace view max_view as select unitcode, max(mark) as max_mark from enrolment group by unitcode;select e.studid, e.unitcode, e.markfrom max_view v join enrolment e on e.unitcode = v.unitcode; Join Self Join 123select *from employee e1 join employee e2on e1.mgrno = e2.empno; Full Join 12select * from student s full outer join mark m on s.id = m.id; Left Join 123select * fromstudent s left outer join mark mon s.id = m.id; Right Join 123select * fromstudent s right outer join mark mon s.id = m.id; Relationship Weak A weak relationship, also known as a non-identifying relationship, exists if the primary key of the related entity does not contain a primary key component of the parent entity. Strong A strong (identifying) relationship exists when the primary key of the related entity contains a primary key component of the entity. Normalisation Unormalisation Form The UNF representation of a relation is the representation which you have mapped from your inspection of the form, and no primary key etc have as yes beeen identified. Fist Normal Form A unique primary key has been identified for each tuple/row It is a valid relation : entity integrity(no part of PK is null); single value for each cell (no repeating group) All attributes are functionally dependent on all or part of the primary key UNF to 1NF : Elminate the repeating groups Identify the primary key Identify all dependencies 1NF to 2NF : Make new tables to eliminate partial dependencies 2NF to 3NF : Make new tables to eliminate transitive dependencies]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度下降]]></title>
    <url>%2F2019%2F05%2F16%2F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%2F</url>
    <content type="text"><![CDATA[梯度下降 梯度下降是机器学习优化中常用的算法，因为凸函数 (convex function) 沿着负梯度方向移动一定能够到达全局最小值 (global minimum)，在实际应用中由于损失函数大多数情况下不能保证为凸函数，因此梯度下降法更可能在局部 (局部凸函数) 找到局部极小值 (local minimum). 什么是梯度 首先梯度 (gradient) 是一个向量，这样意味着梯度是有方向的. 在迭代过程中，通过沿着函数的负梯度方向慢慢移动，可以最快速的找到局部极小值. 而梯度的值本身是某一点的所有方向导数中值最大的一个. 为什么梯度是函数下降最快的方向 为了解释这个问题，首先需要明确方向导数和偏导数的概念. 其中方向导数是指在多位空间内对某一方向求导得出的导数，对于空间内某一点来说，其方向导数有很多个；偏导数是指函数沿着某一特定坐标轴方向的导数，也是函数沿着该方向的变化率. 对于空间内的一点来说，我们能够很容易的求得给个自变量所对应的偏导数，对于二元函数来说 : \[\nabla f = \left[ \begin{matrix} f_x(x,y) \\ f_y(x,y) \end{matrix} \right]\] 根据空间向量的知识可以很容易的知道：空间内任意方向都可以由一组不共线的向量组成 : \[D = f_xcos\theta + f_ysin\theta\] 设\(A=(f_x,f_y)\), \(I = (cos\theta, sin\theta)\)，根据向量内积的公式可得 : \[A⋅I = |A|⋅|I|⋅cos\alpha\] 其中\(\alpha\)是向量\(A\)和向量\(I\)的夹角度. 由上面的公式可以看出，当\(cos\alpha\)值为1时，\(\alpha\)为0度 (也就是\(I\)与\(A\)平行时)，方向导数最大. 也就是说函数沿着与向量\((f_x, f_y)\)平行的反方向移动时，在局部的下降速度是最快的. 更新参数 有了梯度向量，我们在每次更新参数时就变得非常容易了，只要在每次迭代中向梯度方向移动就可以了 : \[w&#39;_i = w_i - \alpha {\partial L \over \partial w_i }\]]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAT9004复习总结(1)]]></title>
    <url>%2F2019%2F05%2F15%2FMAT9004%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%931%2F</url>
    <content type="text"><![CDATA[MAT9004复习总结 快到期末了......最近在复习MAT9004这门课，这门课主要讲的是高数、线性代数和概率论的一些基础知识，lecture上一般讲的比较简单，但每个知识点的切入点都很不错，在复习过程中有一些困惑，结合一些资料以及之前的知识储备浅略的探索了一下，总结的可能比较零碎，如果篇幅较长的话后期再做分类整理. 一阶近似引出的点 首先给出一阶近似(first order approximation)的概念 : \[f(x_0+ \Delta x) \approx f(x) + f&#39;(x)\Delta x\] 对于二元函数 : \[f(x + \Delta x, y + \Delta y) \approx f(x, y) + f_x (x, y) \Delta x + f_y (x, y) \Delta y\] 这里的一阶近似就是一阶泰勒展式，这里可以联想到几处知识点，泰勒公式，海森矩阵，极值点判定和牛顿法. 泰勒公式 泰勒公式(Taylor's Formula)本质上是用多项式函数对光滑函数进行逼近，也就是在\(x_0\)处用\(n\)阶多项式模拟(逼近)复杂函数 : \[f(x)=\sum_{n=0}^N {f^{n}(a) \over n!} (x-a)^n + R_n(x)\] 表示函数在\(a\)处的泰勒展式，其中\(R\)是余项，是对误差的近似估计. 这里除以\(n!\)是为了惩罚高阶多项式，应为当低阶和高阶相加时，由于幂函数增长速度非常快，导致低阶的特性完全没覆盖，因此通过施加这种惩罚来让多项式在\(x\)值较小时呈现出低阶的特性，随着\(x\)的增大再显现处高阶特性. 至于为什么泰勒公式可以实现在\(x_0\)处，用一个多项式函数去近似一个复杂函数，这是因为本质上泰勒公式的做法是让近似多项式函数在 \(x=x_0\)处的\(y\)值，一阶导数，二阶导数，......，n阶导数 \(=\) 原函数在 \(x=x_0\)处的\(y\)值，一阶导数，二阶导数，......，n阶导数，即近似函数和原函数在某点的值一样，变化率一样，变化率的变化率一样，变化率的变化率的变化率也一样......至于为什么要这样做，这里引用知乎上的一个举例 ： 一小滑块以\(v_0\)的初速度，从\(x=S_0\)处运动(以向右为正方向)，求\(t\)时小滑块的路程\(S\). \[S=S_0+v_0t, S&#39;=v_0\] 一小滑块以\(v_0\)的初速度，\(a\)的加速度，从\(x=S_0\)处运动(以向右为正方向)，求\(t\)时小滑块的路程\(S\). \[S = S_0 + v_0t + {1\over2}at^2, S&#39;=v_0+at, S&#39;&#39;=a\] 一小滑块以\(v_0\)的初速度，\(a\)的初加速度，\(b\)的初加加速度，从\(x=S_0\)处运动(以向右为正方向)，求\(t\)时小滑块的路程\(S\). 这里加加速度其实就是加速度对时间的导数 : \[S=S_0 + v_0t + {1\over2}at^2 + {1\over6}bt^3, S&#39;=v_0+at+{1\over2}bt^2,S&#39;&#39;&#39;=a+bt,S&#39;&#39;&#39;&#39;=b\] 总结一下上面的规律可以发现 : \[S=S_0+{1\over1!}v_0t + {1\over2!}at^2 + {1\over3!}bt^3\] 我们继续往后扩展 : 一小滑块以\(v_0\)的初速度，\(a\)的初加速度，\(b\)的初加加速度，\(c\)的初加加加速度，\(d\)的初加加加加速度......，从\(x=S_0\)处运动(表征了一个小滑块的任意运动情况)(以向右为正方向)，求\(t\)时小滑块的路程\(S\). 根据上面找到的规律 : \[S=S_0+{1\over1!}v_0t + {1\over2!}at^2 + {1\over3!}bt^3 + {1\over4!}ct^4 + {1\over5!}dt^5...\] 因此规律可以归结为 : \[S={S_0\over0!}+{S^{(1)}\over1!}v_0t + {S^{(2)}\over2!}at^2 + {S^{(3)}\over3!}bt^3 + {S^{(4)}\over4!}ct^4 + ... +{S^{(n)}\over n!}dt^n\] 这个例子形象说明了无论小滑块沿着直线如何运动，我们只要从初始点开始，把整个过程中每一处加速度的变化，加速度变化的变化，加速度变化的变化的变化......全部计算进去，就能够得到最终所到达的位置. 而在实际应用中由于不可能将这些变化全部考虑进去，因此得到的就是原函数的近似值(approximation)，这也就是泰勒公式用多项式函数逼近复杂函数的大致过程. 海森矩阵 海森矩阵(The Hessian Matrix) 是由函数的二阶偏导数组成的n阶方块矩阵，二元函数的海森矩阵 : \[H(x) = \left[ \begin{matrix} f_{xx}(x,y) &amp; f_{xy}(x,y) \\ f_{yx}(x,y) &amp; f_{yy}(x,y) \end{matrix} \right] \] 其一阶导向量，也就是梯度向量为 : \[\nabla f = \left[ \begin{matrix} f_x(x,y) \\ f_y(x,y) \end{matrix} \right]\] 对于n元函数，\(x=(x_1, x_2, x_3,...,x_n)\)，Hessian Matrix 表示为 : \[\begin{bmatrix} \frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1\,\partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_1\,\partial x_n} \\ \\ \frac{\partial^2 f}{\partial x_2\,\partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_2\,\partial x_n} \\ \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \\ \frac{\partial^2 f}{\partial x_n\,\partial x_1} &amp; \frac{\partial^2 f}{\partial x_n\,\partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_n^2} \end{bmatrix}\] 海森矩阵可以应用于判定极值点以及牛顿法解决大规模优化问题. 极值点判定 我们可以应用上一节提到的Hessain Matrix判定极值点是否存在. 首先需要计算Hessian Matrix的行列式(determinate) : \[D = det(H(x, y))\] 将能够使一阶导为零的点\((x,y)\)代入上式 : if \(D &gt; 0\), \((x,y)\) 是极值点(local extrema); if \(D = 0\), 判定无意义 (inconclusive); if \(D &lt; 0\), \((x,y)\) 是鞍点 (saddle point). 其中鞍点 (saddle point) 是指从不同的角度来看，该点是不同类型的极值点 (In one direction it looks like a local maximum, while in another direction it looks like a local minimum). For local extrema : if \(f_{xx} &gt; 0\), then \((x,y)\) is a local minimum; if \(f_{xx} &lt; 0\), then \((x,y)\) is a local maximum. 同时二阶导和海森矩阵也能够判断函数的凹凸性 : \(f\) is convex if and only if for all \((x,y) \in R^2\), \(f_{xx},f_{yy} \geq 0, det(H(x,y)) \geq 0\) \(f\) is convex if and only if for all \((x,y) \in R^2\), \(f_{xx},f_{yy} \leq 0, det(H(x,y)) \geq 0\) 对于凹函数和凸函数来说 : A local minimum point of a convex function is also a global minimum A local maximum point of a concave function is also a global maximum 牛顿法 这个模块主要记录一下牛顿法以及牛顿法和梯度下降的区别. (越写越多，坑真的大......) 明天再写吧，扩展太多怕是复习不完了...... 牛顿法介绍 牛顿法与梯度下降 References 泰勒公式图像解释 如何通俗的理解泰勒公式@单手倒立拍星轨 Jacobian矩阵和Hessian矩阵 Hessian Martix--Wikipeida]]></content>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 总结]]></title>
    <url>%2F2019%2F05%2F14%2Fshell-%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Shell Summary]]></content>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协同过滤]]></title>
    <url>%2F2019%2F05%2F14%2F%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[Auto Encoder]]></title>
    <url>%2F2019%2F05%2F12%2FAuto-Encoder%2F</url>
    <content type="text"><![CDATA[Auto Encoder Auto encoder is a kind of method to reduce the dimension of input data, it's a shallow neural network which learning the weights by back propagation. By this algorithm, the auto encoder can learn the useful features automatically, so it's always used in feature extraction and generally has a better performance than PCA, which is another common way to reduce dimensions. A typical auto encoder is consist of encoder and decoder : auto coder As the above picture shows, firstly, the encoder transfer the input into \(y=f(x)\), and then it will be decoded into \(g(y)=g(f(x))\). Auto encoder is a kind of unsupervised learning algorithm, the main target of it is going to encode the input data \(x\) according to the output which is decoded from \(y\), that means the algorithm tries to copy its input to its output, the auto encoder modifies the weights in the hidden layer as well as the output layer according to calculate the difference (we call this as loss function or cost function). Here is the graph of the auto encoder, shown in neural network : neural network The formulas of the above neural network are, where \(L\) means the loss function (usually squared error or cross entropy loss) : \[y=f(x)=s(w1*x+b1)\] \[\hat{x}=g(y)=s(w2*x+b)s\] \[L(x, \hat x) = L(x, g(f(x)))\] feature extracting method in recent few years.]]></content>
      <categories>
        <category>Feature Engineering</category>
      </categories>
      <tags>
        <tag>Feature Engineering</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[隐语义模型(LFM)]]></title>
    <url>%2F2019%2F05%2F08%2F%E9%9A%90%E8%AF%AD%E4%B9%89%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[隐语义模型 关于隐语义模型(latent factor model)的介绍，项亮博士在《推荐系统实践》中有过介绍，这本书的确是推荐系统方向非常非常棒的书籍. 我在用python实现书中隐语义模型时遇到了一些问题和坑，因此用这篇博客进行记录并总结，之后有新的或更深的理解会及时更新本文. 关于Latent Factor Model 隐语义模型本质上是通过对用户历史行为中的items进行聚类，从而完成推荐. 这样做的好处在于我们不需要对样本进行标记，在分类过程中也不需要关心类别的可解释性. LFM通过在用户和物品中构建一个“中间层”的方式来建立联系，使用算法自动得到物品和用户的分类权数. LFM通过以下模型来衡量这层关系: \[R_{UI} = P_{U}*Q_{I} = \sum_{k=1}^K p_{uk}*q_{ki}\] 其中\(K\)为“中间层”中隐类的个数，我们笼统的把用户历史行为中的物品划分为\(K\)个类，每个类对于每个用户都学习一个权重参数，表示该类在用户历史行为中的权重，公式中\(P_{uk}\)用来衡量用户和\(K\)个类别的关系；\(Q_{ki}\)用来衡量每个物品和\(K\)个类之间的关系，LFM模型需要学习每个物品所占每个类的权重参数，我们将两者相乘就可以得到用户对每个物品的兴趣度. 对于模型，我们首先需要定义好损失函数： \[C = \sum_{(u,i)\in k}^K (r_{ui} - \hat{r_{ui}})^2 = \sum_{(u,i)\in k}^K (r_{ui} - \sum_{k=1}^K p_{uk}*q_{ki})^2 + \lambda ||p_u||_2^2 + \lambda ||q_i||_2^2\] 为了优化目标函数，我们还需要对 \(p\) 和 \(q\) 分别求出其一阶偏导数(partial derivertive) : \[{\partial{C}\over p_{uk}} = 2(r_{ui} - \sum_{k=1}^K p_{uk}*q_{ki})(-q_{ki}) + 2\lambda p_{uk} = 2*error*(-q_{ki}) + 2\lambda p_{uk}\] \[{\partial{C}\over q_{ki}} = 2(r_{ui} - \sum_{k=1}^K p_{uk}*q_{ki})(-p_{uk}) + 2\lambda p_{ki} = 2*error*(-p_{uk}) + 2\lambda q_{ki}\] 之后，我们需要在每次迭代时使用梯度下降法更新这两个权重参数 : \[p_{uk} = p_{uk} - \alpha {\partial{C}\over p_{uk}}\] \[q_{ki} = q_{ki} - \alpha {\partial{C}\over q_{ki}}\] LFM实现 初始化模型 根据书中的代码，模型训练之前需要首先初始化模型，即初始化两个权重的值. 可以直接使用numpy.random.rand() 函数 : 123456def init_model(self): for user in self.user_item.keys(): self.P[user] = np.random.rand(self.K) for item in self.item_pool: self.Q[item] = np.random.rand(self.K) 采样 对于每一个用户，根据物品的流行度进行负采样，即根据物品的热门程度构建负样本，因为我们一般认为如果用户没有对热门物品有交互行为，可能意味着用户对其不感兴趣，而对于长尾物品，用户可能未曾有交互机会，因此不能够一定程度上认定对其不感兴趣，以下为采样函数 : 1234567891011121314151617def collect_samples(self, items): # collect positive samples labels = dict() for movie in items: labels[movie] = 1 # collect negative smaples n_negative = 0 seen = set(items) pos_num = len(seen) item = np.random.choice(self.items, int(pos_num*self.ratio*3), self.pops) item = [x for x in item if x not in seen][:int(pos_num*self.ratio)] for i in item: labels[i] = 0 return labels 训练 在训练中，根据上文中提到的公式进行迭代训练，优化损失函数 : 12345678910for epoch in range(self.epoches): for user, items in self.user_item.items(): samples = self.collect_samples(items) # samples : &#123;movie_id : label&#125; for item, label in samples.items(): error = label - self.predict(user, item) self.P[user] += self.alpha * (error * self.Q[item] - self.lambda_r * self.P[user]) self.Q[item] += self.alpha * (error * self.P[user] - self.lambda_r * self.Q[item]) 推荐 对每一个不在用户历史交互列表中的物品，计算推荐分数，然后从高到低排序，选取前N个作为推荐结果 : 1234567891011def recommend(self, user, N): iteracted_item = self.user_item[user] recommend_score = dict() for item in self.item_pool: if item not in iteracted_item: # recommend_score : item_id : score recommend_score[item] = np.dot(self.P[user], self.Q[item]) recs = sorted(recommend_score.items(), reverse=True, key=lambda x:x[1])[0:N] return recs 问题总结 负样本采集 因为这里我们把用户对电影完成评分这一行为作为正样本，因此在构造训练集时需要采集相应的负样本，根据书中的介绍，在采集负样本时，应尽量选取和正样本数量相同且较热门的物品. 我在最初的尝试中每次训练时对用户按照物品流行度降序选取相同的物品，过程中发现 loss 可以下降到比较低的数值，但 recall 一直停留在 1.5 左右，且覆盖率较高(接近50%)，我认为这种方法在推荐过程中过于随机化 : recall precision coverage popularity 1.63 5.42 46.55 5.61 更加合理的方式是按照流行度随机采集负样本，这里我尝试了两种不同的方法. 将所有用户历史行为中的物品存储在 list 中，每次采样时随机抽取，由于流行度越高的物品出现的次数越多，因此这种抽取方式理论上实现了按照物品热度采用的思想. 但实际效果并不理想，原因在于用户交互过的物品有限，当采用次数没有达到一定量级时，不能保证尽可能的选出热门物品，可以看到此时 recall 和 precision 有明显提升： recall precision coverage popularity 5.31 17.63 47.47 3.89 按照物品出现的概率采样是我实验中发现效果比较好的方式，统计每种物品的出现次数，用numpy.ramdom.choice()函数按概率取样，发现 recall 和 precision 有明显提升，但覆盖率有所下降: recall precision coverage popularity 7.74 24.66 41.90 6.81 负样本的采集对结果具有决定性的影响，每次选取不同的负样本进行训练具有更好的效果. 正则化参数 正则化的最用和意义在我另一篇文章中有较详细的介绍: Regularization in Machine Learning. 当正则化参数较大时，对模型的惩罚加大，损失函数可能会一直居高不下，下降缓慢并在较大值处收敛，这是由于模型较简单所导致的，可以根据结果调整参数大小，一般当 K 值较小时倾向于选取较小的正则化参数. References 隐语义模型 (LFM) 推荐算法 隐语义模型 code from github]]></content>
      <categories>
        <category>Recommender System</category>
        <category>Neighbourhood-based</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019.5.2 近期问题总结]]></title>
    <url>%2F2019%2F05%2F02%2F2019-5-2-%E8%BF%91%E6%9C%9F%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[2019.5.2 近期问题总结 pandas 过滤数据后比较 pandas 使用 loc()方法过滤(获取)到的数据不能够直接在if, while, for等语句中和其它常用类型直接比较. 对于一次过滤后的数据，如果需要用上述语句进行比较，需要进行数据类型转换： 123rating = int(ratings.loc[(ratings['user_id'] == u) &amp; (ratings['movie_id'] == movie)]['rating'])if rating &gt;= threshold: pass 其中，有多个过滤条件时需要用&amp;连接. 使用 list 创建多维数组 使用 list 创建多维数组时，如果对某一 list 直接复制： 12a = [0,1,2]b = [a] * len(a) 因为单纯的这样复制属于浅拷贝，b中其余各行依旧指向 list a 所在的地址，因此当数组中有一行发生变动时，其余行将会受到影响： 1234567for i in range(len(b)): for j in range(len(b)): if i == j: continue b[i][j] += 3b&gt;&gt;&gt; [[6, 7, 8], [6, 7, 8], [6, 7, 8]] 当需要用 list 创建多维数组时，采用： 123456789a = [0,1,2]b = [[0 for i in range(len(a))] for i in range(len(a))]for i in range(len(b)): for j in range(len(b)): if i == j: continue b[i][j] += 3b&gt;&gt;&gt; [[0, 3, 3], [3, 0, 3], [3, 3, 0]] 当某行发生变化时其余数据不受影响. numpy 合并/拼接 array 按行(上下)合并 将多个一维数组按行合并为多维时，可以采用np.vstack()方法: 123456A = np.array([1,1,1])B = np.array([2,2,2])np.vstack((A,B)) # vertical stack&gt;&gt;&gt; [[1,1,1] [2,2,2]] 左右合并 可以使用np.hstack()方法： 12D = np.hstack((A,B)) # horizontal stack&gt;&gt;&gt; [1,1,1,2,2,2] np.append()方法： 12E = np.append(A,B) # horizontal stack&gt;&gt;&gt; [1,1,1,2,2,2] 转置 按行转置： 12A[np.nexaxis,:]&gt;&gt;&gt; [[1,1,1]] 按列转置： 1234A[:,np.nexaxis]&gt;&gt;&gt; [[1], [1], [1]] concatenate： 1234567891011a=np.array([[1,2,3],[4,5,6]])b=np.array([[11,21,31],[7,8,9]])# 合并行np.concatenate((a,b,c),axis=0) # 默认情况下，axis=0可以不写&gt;&gt;&gt; array([[ 1, 2, 3], [ 4, 5, 6], [11, 21, 31], [ 7, 8, 9]])# 合并列np.concatenate((a,b),axis=1) &gt;&gt;&gt; array([[ 1, 2, 3, 11, 21, 31],[ 4, 5, 6, 7, 8, 9]])]]></content>
      <categories>
        <category>踩坑</category>
      </categories>
      <tags>
        <tag>踩坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Decision Tree]]></title>
    <url>%2F2019%2F04%2F14%2FDecision-Tree%2F</url>
    <content type="text"><![CDATA[About Decision Tree Decision Tree is a kind of common classification and regression algorithm in machine learning, although it's a basic method, some advanced learning algorithms such as GBDT (Gradient Boosting Decision Tree) are established on it. There are approximate three steps in decision tree learning: feature selection, decision tree generating and decision tree pruning. In the essence, decision tree splits the data set according to the information gain, which means this algorithm chooses the features which can make the data set has the minimum uncertainty in each steps. In this blog, I'm going to introduce the feature selection, decision tree generating and decision tree pruning respectively, and the classification and regression tree (CART) will be detailedly interpreted. All the codes in this atricle are collected on my github: Decision Tree Feature Selection We need a calculation method or regulation to mark each features in the data set since the essence of decision tree learning is splitting the data set based on features, in other word, we need to determine which feature will be the 'hero' or the 'entrance' in the next level of the decision tree. Therefore, we need to calculate the information gain for the current data set. Entropy and Conditional Entropy For better understanding the information gain, we need to know the concept of entropy first. The entropy is defined as 'a metric can represent the uncertainty of random variable' , assume \(X\) is a random variable, such that the probability distribution is: \[P(X=x_i) = p_i, (i=1,2,3,...,n)\] And the entropy of \(X\) is: \[H(p) = -\sum_{i=1}^n p_i * log(p_i)\] A large entropy represents a large uncertainty, and the range of \(H(p)\) is: \[0 \leq H(p) \leq log(n)\] If we assume there is a random variable \((X,Y)\), and the union probability distribution is: \[P(X=x_i, Y=y_j) = p_{ij}, (i=1,2,...,n; j=1,2,...,m)\] And the conditional entropy is: \[H(Y|X) = \sum_{i=1}^n p_i * H(Y|X=x_i)\] Which represents the uncertainty of random variable \(Y\) with the given random variable \(X\). In this situation, we call entropy and the conditional entropy as empirical entropy and empirical conditional entropy. Information Gain Concept of Information Gain Now we can learn what is information gain. As the definition, 'information gain represents the degree of reduction of the uncertainty of class \(Y\) by giving the feature \(X\)'. Here we use \(D\) to denote the data set, and \(A\) to denote the specific feature, and the information gain of feature \(A\) for data set \(D\) is the difference of empirical entropy and empirical conditional entropy: \[g(D, A) = H(D) - H(D|A)\] We can easily know that different features always have different information gain, a feature with large information has strong ability on classification. Process of Calculating Information Gain calculate the empirical entropy \(H(D)\): \[H(D) = -\sum_{k=1}^K {|C_k|\over |D|} * log_2{|C_k|\over |D|}\] calculate the empirical conditional entropy of feature \(A\): \[H(D|A) =\sum_{i=1}^n {|D_i|\over |D|} * H(D_i)=-\sum_{i=1}^n {|D_i|\over |D|} * \sum_{k=1}^K {|D_{ik}|\over |D_i|} * log_2{|D_{ik}|\over |D_i|}\] calculate the information gain: \[g(D, A) = H(D) - H(D|A)\] Where: \(C_k\) represents the classes, \(|C_k|\) is the amount of class \(C_k\), and \(\sum_{k=1}^K|C_k|=|D|\); \(D_i\) represents the subsets which are splitted according to the feature \(A\), and \(\sum_{i=1}^i|D_i|=|D|\); \(D_{ik}\) represents the subset which all the elements are belong to the class \(C_k\) in the subset \(D_i\) Information Gain Ratio Since splitting the data set by using information gain approach may tends to select the features with more values in some situations, we can use another method named information gain ratio to solve this problem. Information gain ratio, as its name, is the ratio of the information gain and empirical entropy: \[g_R(D,A) = {g(D,A) \over H_A(D)}\] Decision Tree Generation I'm going to introduce two decision tree generating algorithms which are ID3 and C4.5, the former method will be mainly introduced. In addition, the process of generation and pruning of CART will be explained in the next part. ID3 Algorithm ID3 algorithm splits the data set by using the features which have the largest information gain value, and generate the decision tree recursively. The process of the algorithm is: Steps Setting \(T\) as the leaf node and use\(C_k\) as the class label if all the distances in subset \(D\) are belong to class \(C_k\), return \(T\); If there is no further features meet the requirement (the value of information gain less than the threshold), setting \(T\) as the leaf node and use the class of most distances as label, return \(T\); Otherwise, calculating the information gain values of each features for data set \(D\), choosing the largest one as \(A_g\) which will be the splitting point; For each possible values (\(a_i\)) in \(A_g\), splitting the data set into plenty of subsets \(D_i\) by \(A_g = a_i\), use the class of most distances in each subset \(D_i\) as labels, return \(T\); For each sub-nodes in step 4, use \(D_i\) as training set, \(A-A_g\) as feature set, execute the step 1 to 4 recursively until meet the stopping conditions, return \(T_i\) Code Import the necessary third-party libraries : 1234567891011121314import numpy as npimport pandas as pdimport matplotlib.pyplot as plt%matplotlib inlinefrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom collections import Counterimport mathfrom math import logimport sysimport pprint First we calculate the information gain value : 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# empirical entropydef cal_entropy(self, datasets): n = len(datasets) label_count = &#123;&#125; # get distribution(Pi) for i in range(n): label = datasets[i][-1] if label not in label_count: label_count[label] = 0 label_count[label] += 1 empirical_entropy = -sum([(p/n) * log(p/n, 2) for p in label_count.values()]) return empirical_entropy# empirical conditional entropydef cal_conditional_entropy(self, datasets, axis=0): n = len(datasets) feature_sets = &#123;&#125; for i in range(n): feature = datasets[i][axis] if feature not in feature_sets: feature_sets[feature] = [] feature_sets[feature].append(datasets[i]) empirical_conditional_entropy = sum([(len(p)/n) * self.cal_entropy(p) for p in feature_sets.values()]) return empirical_conditional_entropy# calculate the difference between two entropydef info_gain(self, entropy, con_entropy): return entropy - con_entropy# calculate information gaindef get_info_gain(self, datasets): feature_count = len(datasets[0]) - 1 empirical_entropy = self.cal_entropy(datasets) best_feature = [] for c in range(feature_count): c_info_gain = self.info_gain(empirical_entropy, self.cal_conditional_entropy(datasets, axis=c)) best_feature.append((c, c_info_gain)) best = max(best_feature, key=lambda x : x[-1]) # best : ((feature_id, feature_info_gain)) return best Define the class Node as : 123456789101112class Node: def __init__(self, splitting_feature_id=None, class_label=None, data=None, splitting_feature_value=None): self.splitting_feature_id = splitting_feature_id # splitting feature self.splitting_feature_value = splitting_feature_value # splitting feature value self.class_label = class_label # class label, only leaf has self.data = data # labels of samples, only leaf has self.child = [] # child node def add_node(self, node): self.child.append(node) Then achieve the ID3 algorithm : 123456789101112131415161718192021222324252627282930313233343536373839404142def train(self, train_data, node): _ = train_data.iloc[:, :-1] y_train = train_data.iloc[:, -1] features = train_data.columns[:-1] # 1. if all the data in D belong to the same class C, # set T as single node and use C as the label, return T if len(y_train.value_counts()) == 1: node.class_label = y_train.iloc[0] node.data = y_train return # 2. if feature A is empty, set T as single node and use the label, # most C as the label, return T if len(features) == 0: node.class_label = y_train.value_counts().sort_values(ascending=False).index[0] node.data = y_train return # 3. calculate the largest inforamtion gain, use Ag to represents the best feature max_feature_id, max_info_gain = self.get_info_gain(np.array(train_data)) max_feature_name = features[max_feature_id] # 4. if the information gain is smaller than threshold, set T as single node, # and use the most C as the label, return T if max_info_gain &lt;= self.epsilon: node.class_label = y_train.value_counts().sort_values(ascending=False).index[0] node.data = y_train return # 5. splitting D according to each possible values in the feature A feature_list = train_data[max_feature_name].value_counts().index for Di in feature_list: node.splitting_feature_id = max_feature_id child = Node(splitting_feature_value = Di) node.add_node(child) sub_train_data = pd.DataFrame([list(i) for i in train_data.values if i[max_feature_id] == Di], columns = train_data.columns) # 6. create tree recursively self.train(sub_train_data, child) C4.5 Algorithm The C4.5 algorithm becomes extremely easy to understand after introducing the ID3 algorithm, cause there's only one different point between the two methods, that is C4.5 algorithm uses information gain ratio to choose the splitting feature instead of using information gain, besides this, other steps in C4.5 are same with those in ID3 algorithm. Decision Tree Pruning A Simple Pruning approach In this part, we just discuss the pruning algorithm for ID3 and C4.5, the pruning for CART will be interpreted in the next part. We have discussed the decision tree generating approached in the above part, however, it can overfit easily if there're lots of levels in the decision tree, so we need to prune the tree to avoid overfitting and simplify the process of calculating. Specifically, we cut some leaf nodes or sub-tree from the original tree and use their parents nodes as the new leaf nodes. Like the other machine learning algorithms, here we prune the decision tree by minimising the loss function. Assume that \(|T|\) is the number of leaf nodes, \(t\) represents the leaf nodes and there are \(N_t\) samples in it, use \(N_{tk}\) to denote the number of samples which belong to class \(k\) in \(N_t\), where \(k=1,2,...,K\) ; \(H_t(T)\) is the empirical entropy of leaf node \(t\), then define the loss function as : \[C_\alpha(T) = \sum_{t=1}^{|T|}N_t*H_t(T) + \alpha|T|\] We define the training error as : \[C(T) = \sum_{t=1}^{|T|}N_t*H_t(T) = -\sum_{t=1}^{|T|}\sum_{k=1}^KN_{tk} * log {N_{tk}\over N_t}\] In the above formula, the term \(|T|\) which the number of leaf nodes, can represent the complexity of decision tree, the parameter \(\alpha\), can be understood as the coefficient of regularization, so the term \(\alpha|T|\) actually has the same function with regularization term, which can find the trade-off between the complexity and precision of model. A larger \(\alpha\) can promote to choose a simple model and a smaller \(\alpha\) promote to choose a complex model. Our pruning algorithm is going to find the sub-tree with the minimum loss function, here we calculate the loss value \(C_\alpha(T)\) for the current tree, then calculating it again after cutting the brunch (sub-tree) or leaf node, now we get two different information gain values, record as \(C_\alpha(T_B)\) and \(C_\alpha(T_A)\), so we can determine whether it's worth to cut this brunch or not by comparing the two error values, the specific steps are : Calculating the empirical entropy for each leaf nodes; Going back to the parents nodes recursively, cutting the brunch and comparing the error values between before cutting and after cutting, if \(C_\alpha(T_A) \leq C_\alpha(T_B)\), saving the pruning action and setting the parent node as the new leaf node, otherwise, recover the original tree; Repeating the step 2 until all the nodes have been checked, then get the sub-tree with the minimum loss function Code First, we need to achieve the loss function which is the \(C_\alpha(T)\) in the above formula : 1234567891011121314151617181920212223242526272829303132# calculate C_alpha_T for current sub-treedef c_error(self): leaf = [] self.find_leaf(self.tree, leaf) # count the N_t, len(leaf_num) == |T| leaf_num = [len(l) for l in leaf] # calculate empirical entropy for each leaf nodes entropy = [self.cal_entropy(l) for l in leaf] # alpha * |T| alpha_T = self.alpha * len(leaf_num) error = 0 C_alpha_T = 0 + alpha_T for Nt, Ht in zip(leaf_num, entropy): C_T = Nt * Ht error += C_T C_alpha_T += error return C_alpha_T # find all leaf nodes def find_leaf(self, node, leaf): for t in node.child: if t.class_label is not None: leaf.append(t.data) else: for c in node.child: self.find_leaf(c, leaf) Then calculate loss value for the original tree, starting pruning : 1234567def pruning(self, alpha=0): if alpha: self.alpha = alpha error_min = self.c_error() self.find_parent(self.tree, error_min) In which the find_parent function corresponds the step 2 in the above principle introduction part : 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970def find_parent(self, node, error_min): ''' leaf nodes : class_label -&gt; not None data -&gt; not None splitting_feature_id -&gt; None splitting_feature_value -&gt; None child -&gt; None --------------------------------------------- other nodes: class_label -&gt; None data -&gt; None splitting_feature_id -&gt; not None splitting_feature_value -&gt; not None(except root) child -&gt; not None ''' # if not the leaf nodes if node.splitting_feature_id is not None: # collect class_labels from child nodes class_label = [c.class_label for c in node.child] # if all the child nodes are leaf nodes if None not in class_label: # collect data from child nodes child_data = [] for c in node.child: for d in list(c.data): child_data.append(d) child_counter = Counter(child_data) # copy the old node old_child = node.child old_splitting_feature_id = node.splitting_feature_id old_class_label = node.class_label old_data = node.data # pruning node.splitting_feature_id = None node.class_label = child_counter.most_common(1)[0][0] node.data = child_data error_after_pruning = self.c_error() # if error_after_pruning &lt;= error_min, it is worth to pruning if error_after_pruning &lt;= error_min: error_min = error_after_pruning return 1 # if not, recover the previous tree else: node.child = old_child node.splitting_feature_id = old_splitting_feature_id node.class_label = old_class_label node.data = old_data # if not all the child nodes are leaf nodes else: re = 0 i = 0 while i &lt; len(node.child): # if the pruning action happend, # rescan the sub-tree since some new leaf nodes are created if_re = self.find_parent(node.child[i], error_min) if if_re == 1: re = 1 elif if_re == 2: i -= 1 i += 1 if re: return 2 return 0 CART As the name of this algorithm -- classification and regression tree, it can apply on both classification and regression, actually the essence of regression tree is based on classification principle, I'm going to explain it later. Regression Tree Principle of Generating The process of generating regression tree is also the procedure of establishing binary decision tree recursively by minimising the mean square error. In the regression problems, we assume the output \(Y\) is continuous variable, so the training set is : \[D = \{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}\] Assume that we have splitted the data set into \(M\) units: \(R_1, R2,...,R_M\) , and there are one unique output value in each units \(R_m\), record as \(c_m\), in other word, we split the training set into plenty of units, and calculate an output or prediction value for each subsets, therefore, the model can be represented as : \[f(x) = \sum_{m=1}^Mc_m\] And we use the mean square error to evaluate the training error for our model : \[\sum(y_i-f(x_i))^2\] In addition, the optimal output value of \(R_m\) is : \[c_m = average(y_i|x_i \in R_m)\] Now, we need to choose the appropriate feature and value to split the data set, we call the chosen feature as splitting variable and the value is splitting point. Actually there's no sample or convenient method to find these two value, what we can do is go through all the features and for possible values of each features, calculate the summary error of the two subsets (units) which are splitted based on the values. The detailed steps are: For the all features, scan possible values, find the specific feature \(j\) and value \(s\) which can guarantee the below formula reaches at the minimum value : \[\min_{j,s} \{ \min_{c_1}\sum_{x_i\in R_1}(y_i-c_1)^2 + \min_{c_2}\sum_{x_i\in R_2}(y_i-c_2)^2 \}\] For the specific \((j,s)\), splitting the data set and calculate the outputs : \[R_1(j,s)=\{x|x^{(j)}\leq s\}, R_2(j,s)=\{x|x^{(j)}\geq s\}\] \[c_m={1 \over N_m} * \sum_{x_i\in R_m}y_i, (x\in R_m, m=1,2)\] Repeat the first two steps recursively, until the deep of level reaches at the previous setting Then we can get the decision tree model : \[f(x) = \sum_{m=1}^Mc_m\] Code First, we define the Node class for the tree as : 1234567891011121314151617181920class Node: def __init__(self, splitting_name=None, splitting_value=None, c=None): ''' leaf : splitting_name --&gt; None splitting_value --&gt; None child --&gt; None c --&gt; Not None ------------------------------- others: splitting_name --&gt; Not None splitting_value --&gt; Not None child --&gt; Not None c --&gt; Not None ''' self.splitting_name = splitting_name self.splitting_value = splitting_value self.child = [] self.c = c def add_node(self, node): self.child.append(node) The mean square error method and the optimal \(c_m\) calculation : 123456789101112def mse(self, r, c): y = np.array(r['target']) error = 0 for i in y: error += np.power((i - c), 2) return errordef get_best_c(self, r): # target is the label feature y = r['target'] return np.mean(y) As for the training part, achieving the above first two steps recursively : 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def train(self, dataset, node, max_depth, depth): ''' @ dataset: the training data @ node: nodes of the tree @ max_depth: the total deep of the tree @ depth: current depth ''' train_data = dataset.iloc[:, 0:-1] # if the data set can't be splitted, return if train_data.shape[0] == 0: return # create two child nodes for each non-leaf nodes child1 = Node() child2 = Node() node.add_node(child1) node.add_node(child2) # initial the error as infinity error_sum = float('inf') # go through the features' values, find the j,s for feature_name in train_data.columns.values: for feature_value in train_data[feature_name]: # split the data set into two units r1_list = [rows for index, rows in dataset.iterrows() if rows[feature_name] &lt; feature_value] r2_list = [rows for index, rows in dataset.iterrows() if rows[feature_name] &gt;= feature_value] r1 = pd.DataFrame(r1_list, columns=dataset.columns) c1 = self.get_best_c(r1) error1 = self.mse(r1, c1) r2 = pd.DataFrame(r2_list, columns=dataset.columns) c2 = self.get_best_c(r2) error2 = self.mse(r2, c2) if (error1 + error2) &lt; error_sum: error_sum = error1 + error2 node.splitting_name = feature_name node.splitting_value = feature_value child1.c = c1 child2.c = c2 print(depth, node.splitting_name, node.splitting_value) # delete the splitting variable r1 = r1.drop(node.splitting_name, axis=1) r2 = r2.drop(node.splitting_name, axis=1) # if has arrived at the last level, return if depth == max_depth: return # repeat the above actions for each childs self.train(r1, child1, max_depth, depth+1) self.train(r2, child2, max_depth, depth+1) return The Idea of Classification As we said, the essence of regression tree is based on the idea of classification principle, and now I'm going to give the interpretation. In the above part, we mentioned that using the average value of the labels as the output in each subsets (units) which means we seem the each units as a 'class', and the class label is the output \(c_m\). When we need to predict for a new data item, the model just need to classify it according to the splitting variable and splitting point which we found previously, therefore, when the model classify the data into a leaf node, the output \(c_m\) of that leaf node is our prediction value. Here we use a graph to help us to understand it better : As we see, when the max_depth is equal to 1, the data is approximately splitted into two parts, and be classified into more classes when the value of max_depth is 3. Therefore, in fact, the regression tree use the idea of classification to classify the 'similar' samples as a specific class, and use the average value of their labels as the class label, in this way a regression model has achieved. Classification Tree Generating Principle The core concept of generating of classification tree is using the Gini Index to select the optimal features and determine the optimal the binary value splitting point in each levels. Assume that we have \(K\) classes in total, and the probability of sample belongs to the class \(k\) is \(p_k\), so that the Gini Index can be defined as : \[Gini(p) = \sum_{k=1}^K p_k * (1-p_k) = 1 - \sum_{k=1}^K p_k^2\] And for the binary classification problem, we have : \[Gini(p) = 2p * (1-p)\] For a given data set \(D\), there has : \[Gini(D) = 1 - \sum_{k=1}^K ({|C_k| \over |D|})^2\] In which \(C_k\) is the subset of \(D\) which the samples belong to the class \(k\), and \(K\) represents the number of classes. If we split the data set into two parts \(D_1\) and \(D_2\) according to whether the value of feature \(A\) is equal to the possible value \(a\), then the gini index in this situation is : \[Gini(D,A) = {|D_1|\over |D|} * Gini(D_1) + {|D_2|\over |D|} * Gini(D_2)\] Where like the entropy, gini index can also represent the uncertainty of data set, and \(Gini(D,A)\) represents the uncertainty of data set which is splitted by \(A=a\), in addition, still like the entropy, a large gini index value means the large uncertainty. The below steps show the detailed process of classification tree generating : For each feature \(A\), and for its each possible value \(a\), splitting the data set \(D\) into two parts \(D_1\) and \(D_2\) according to whether \(A=a\), calculate the value of \(Gini(D, A)\); For each feature and its possible value, select the optimal feature \(A\) and the splitting point \(a\) which can make \(Gini(D, A)\) has the minimum value, and distribute data set to \(D_1\) and \(D_2\) respectively; For the sub-nodes, repeat the first two steps recursively until there's no further features or reaches at the max depth, or the number of samples in node is less than the threshold which we set previously. Code First, we define the Node class as : 12345678910class Node: def __init__(self, splitting_feature=None, splitting_point=None, class_label=None, label_data=None): self.splitting_feature = splitting_feature self.splitting_point = splitting_point self.child = [] self.class_label = class_label self.label_data = label_data # store the labels of the samples def add_child(self, node): self.child.append(node) Then achieve the gini index calculation : 1234567891011121314151617181920212223242526272829def gini_index(self, data, A, a): ''' @ A: splitting vairable (feature) @ a: splitting point (possible value of A) ''' # splitting the data set accroding to whether A == a D1 = data.loc[data[A] == a] D2 = data.loc[data[A] != a] # count the value of |C_k| respectively D1_label_count = &#123;&#125; for i in range(D1.shape[0]): label = D1.iloc[i, -1] if label not in D1_label_count: D1_label_count[label] = 0 D1_label_count[label] += 1 D2_label_count = &#123;&#125; for i in range(D2.shape[0]): label = D2.iloc[i, -1] if label not in D2_label_count: D2_label_count[label] = 0 D2_label_count[label] += 1 # calculate the gini index gini_D1 = (D1.shape[0] / data.shape[0]) * sum([1 - c_k/D1.shape[0] for c_k in D1_label_count.values()]) gini_D2 = (D2.shape[0] / data.shape[0]) * sum([1 - c_k/D2.shape[0] for c_k in D2_label_count.values()]) return gini_D1 + gini_D2 And achieve the steps in the last part to generate the classification tree : 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465def fit(self, data, threshold): self.train(data, self.tree, threshold)def train(self, data, node, threshold): ''' leaf nodes: splitting_feature --&gt; None splitting_point --&gt; None child --&gt; None class_label --&gt; not None label_data --&gt; not None ---------------------------------------- others : splitting_feature --&gt; not None splitting_point --&gt; not None child --&gt; not None class_label --&gt; None label_data --&gt; None ''' labels = data.iloc[:, -1] train_data = data.iloc[:, 0:-1] features_list = train_data.columns.values # if the number of samples less than the threshold, # setting it as the leaf node and return if len(data) &lt; threshold: # use the most class among samples as the class label node.class_label = labels.value_counts().sort_values(ascending=False).index[0] node.label_data = labels return # if all the samples are belong to the same class, # setting it as the leaf node and return if len(labels.value_counts()) == 1: # use the label of samples as the class label node.class_label = labels.iloc[0] node.label_data = labels return # if there' no data in the data set, just return if train_data.empty: node.class_label = labels.value_counts().sort_values(ascending=False).index[0] node.label_data = labels return # initialize the gini index as positive infinity gini = float("inf") for A in features_list: for a in train_data[A]: gini_c = self.gini_index(data, A, a) if gini_c &lt; gini: feature = A point = a gini = gini_c node.splitting_feature = feature node.splitting_point = point node.add_child(Node()) node.add_child(Node()) D1 = data.loc[data[node.splitting_feature] == node.splitting_point].drop(node.splitting_feature, axis=1) D2 = data.loc[data[node.splitting_feature] != node.splitting_point].drop(node.splitting_feature, axis=1) self.train(D1, node.child[0], threshold) self.train(D2, node.child[1], threshold) return CART Pruning Pruning Algorithm Like the pruning algorithm in ID3 and C4.5, here we also use loss function as the evaluation method, as above, the loss function is defined as : \[C_\alpha(T) = C(T) + \alpha|T|\] In which we call \(\alpha\) as the parameter of regularization. \(C(T)\) represents the training error (here we use gini index, we used the mse in regression tree). A large \(\alpha\) promotes the algorithm to choice a simpler model and a small \(\alpha\) will generate a more complex tree. Since we can find the unique optimal sub-tree \(T_\alpha\) with a given \(\alpha\), therefore, we can prune the original tree recursively : we can define a series \(\alpha\), such as \(\alpha_0&lt;\alpha_1&lt;\alpha_2&lt;...&lt;\alpha_n\), and we can find the corresponding optimal sub-tree \(\{T_0,T_1,T_2,...,T_n\}\). Specifically, assume that \(t\) is a node in original tree, and the loss function for the single node tree which \(t\) is the root node is : \[C_\alpha(t) = C(t) + \alpha\] The loss function for sub-tree which \(t\) is the root node is : \[C_\alpha(T_t) = C(T_t) + \alpha|T_t|\] If \(\alpha = 0\) or \(\alpha\) is extremely small, we have : \[C_\alpha(T_t) &lt; C_\alpha(t)\] When \(\alpha\) increased, we have the below equation with the specific \(\alpha\) : \[C_\alpha(T_t) = C_\alpha(t)\] Increasing \(\alpha\) continually, so we can get : \[C_\alpha(T_t) &gt; C_\alpha(t)\] And when \(C_\alpha(T_t) = C_\alpha(t)\), we have : \[ C(t) + \alpha = C(T_t) + \alpha|T_t|\] \[\alpha = {C(t) - C(T_t) \over |T_t| - 1}\] Where \(t\) has the same value of loss function with \(T_t\), and there are less nodes in \(t\), therefore, we choice \(t\) instead of \(T_t\), which can be seen as the action of pruning. So we can calculate the below equation for each internal nodes in the original tree ; \[g(t) = {C(t) - C(T_t) \over |T_t| - 1}\] Which represents the degree of reduction of loss function after pruning, it means when the given \(\alpha &lt; g(t)\), pruning will increase the total loss function; if \(\alpha &gt; g(t)\), pruning can decrease the total loss function. We choice the smallest value of \(g(t)\) in each step, set that \(g(t)\) as \(\alpha\), \(T_i\) is the optimal sub-tree in the interval \([\alpha_i, \alpha_{i+1})\). Pruning the tree until reach at the root node, we need to increase the value of \(\alpha\) in the process. Below steps show the process of the pruning : Set \(k=0\), \(T=T_0\), \(\alpha=+\infty\) For each interval nodes \(t\), calculate \(g(t)\) : \[g(t) = {C(t) - C(T_t) \over |T_t| - 1}\] \[\alpha = min(\alpha, g(t))\] Prune the sub-tree \(t\) which meets the requirement \(g(t) = \alpha\), set \(t\) as the leaf node and use the most labels in \(t\) as the class label Set \(k=k+1\), \(\alpha_k=\alpha\), \(T_k=T\) Repeat the steps 3 and 4 until there is only a root node with two leaf nodes in the tree Choice the best sub-tree in the set \(\{T_0,T_1,...,T_n\}\) by using cross validation In conclusion, the main idea of CART pruning is calculating the value of \(g(t)\) for each interval nodes, which represents the condition that it's worth to cut the brunch, choice the smallest \(g(t)\) as \(\alpha_i\). And cut the sub-tree where \(g(t)=\alpha\), which means every time we cut the sub-trees which have the smallest \(g(t)\), in this way, with the value of \(\alpha\) increasing (cause every time we choice the smallest \(g(t)\) for \(\alpha\)), there are always exist at least one sub-tree will be pruned, and for each interval \([\alpha_i, \alpha_{i+1})\), there is an unique sub-tree \(T_t\) in corresponding. Repeat the pruning action until there are only root node with two leaf nodes in the original tree, we get a sub-tree set \(\{T_0,T_1,...,T_n\}\) which records all the sub-trees in each pruning step, then select the best tree by cross validation method. In addition, I'm going to interpret why we choice the smallest \(g(t)\) as \(\alpha_i\) and prune that brunch in each step. Since we are going to select the best sub-tree by using cross validation in the final step, here we don't want to miss any possible sub-tree, as we said, a large \(\alpha\) means we want the algorithm to choice a simpler model which in decision tree corresponding to a small sized tree, so when we choice the smallest \(g(t)\) (also the \(\alpha\)) in each step, it's also the process of increasing the value of \(\alpha\), therefore, we can get a set with sub-tree \(\{T_0,T_1,...,T_n\}\) in the decreasing size order. In this way, it's easy to image that our action is cutting the brunches step by step until reach at the root node, it's also easy to interpret and achieve by coding. Actually, it can acquire the same result if we choice the largest \(g(t)\) in each step, but it's not an algorithm with good-interpretation property. Code First is the function of finding all leaf nodes of the given node : 1234567def find_leaf(self, node, leaf): # find all leaf nodes for t in node.child: if t.class_label is not None: leaf.append(t.label_data) else: for c in node.child: self.find_leaf(c, leaf) Then, the gini index achievement and \(g(t)\) calculation : 1234567891011121314151617181920212223242526272829303132def gini_pruning(self, leaf_nodes): gini = 0 for node in leaf_nodes: label_count = pd.value_counts(node) gini_curr = 0 for i in range(len(label_count)): gini_curr += math.pow((label_count[i]/len(node)), 2) gini += 1 - gini_curr return ginidef g_t(self, node): leaf_nodes = [] # find all the leaf nodes self.find_leaf(node, leaf_nodes) # |T_t| T_t = len(leaf_nodes) # C(T_t) C_T_t = self.gini_pruning(leaf_nodes) # collect data labels from leaf nodes labels = [] for n in leaf_nodes: for l in n: labels.append(l) # C(t) C_t = self.gini_pruning(labels) gt = (C_t - C_T_t) / (T_t - 1) return gt Then we use the cut_brunch function to prune and iterate the tree : 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364def cut_brunch(self, node, pruning): ''' leaf nodes: splitting_feature --&gt; None splitting_point --&gt; None child --&gt; None class_label --&gt; not None label_data --&gt; not None ---------------------------------------- others : splitting_feature --&gt; not None splitting_point --&gt; not None child --&gt; not None class_label --&gt; None label_data --&gt; None ''' ''' @ node : the given node @ pruning : a flag to indicate whether the current action is pruning or just go through the tree to calculate the values of g(t) ''' # if is leaf node if node.splitting_feature is None: return # if is not leaf node else: # iterate the tree recursively, from bottom to top self.cut_brunch(node.child[0], pruning) self.cut_brunch(node.child[1], pruning) # calculate the value of g(t) gt = self.g_t(node) # if the action is pruning, find the # alpha = g(t) and cut the brunch if pruning: if gt == self.alpha: # collect the labels from leaf nodes leaf_label = [] self.find_leaf(node, leaf_label) labels = [] for n in leaf_label: for l in n: labels.append(l) label_count = Counter(labels) # pruning node.splitting_feature = None node.splitting_point = None node.child[0] = None node.child[1] = None node.label_data = labels # use the most labels in the child nodes as the class label node.class_label = label_count.most_common(1)[0][0] # add current tree T_t to the sub-tree list self.sub_tree.append(copy.deepcopy(self.tree)) # otherwise, the action is calculating the value of g(t) # update the value of alpha if g(t) &lt; alpha else: # alpha = min(alpha, g(t)) if gt &lt; self.alpha: self.alpha = gt return Finally, define a function to achieve the process of the pruning algorithm : 123456789101112131415161718192021222324def pruning(self): # initalize the alpha as positive infity self.alpha = float('inf') # define the alpha and sub-tree list alpha_set = [] self.sub_tree = [] # add the first original tree to the list self.sub_tree.append(copy.deepcopy(self.tree)) # repeat the pruning until there are only root node with two # leaf nodes in the tree while self.tree.child[0].splitting_feature != None or self.tree.child[1].splitting_feature != None: # first, iterate the tree, calculate the value of g(t) self.cut_brunch(self.tree, False) # then, iterate the tree again, prune the brunch # where alpha = g(t) self.cut_brunch(self.tree, True) # add alpha into list and reset the 'new' alpha alpha_set.append(self.alpha) self.alpha = float('inf') # add the last sub-tree, which only includes a root node # with two leaf nodes self.sub_tree.append(self.tree) Different between ID3 and CART ID3, C4.5 and CART are all the algorithms in decision tree, since there's tiny different between ID3 and C4.5, here I just compare the two algorithms : ID3 and CART. The generating principle. In ID3 algorithm, we use information gain to determine the data set splitting, we choice the feature which has the largest value of information gain in each step, split the data set into plenty of units according to \(A_i = a_i\), which means the decision tree which is generated by ID3 may not be a binary tree, it's depends on the possible value of splitting features. However, in CART, we use Gini index as the splitting condition, we choice the feature which has the smallest gini index value in each step, split the data set according to whether \(A_i = a_i\), that means the CART is a binary tree. The similarity of two algorithms is on iterating, both the two methods need to calculate the information gain or gini index for each possible values for each features in each step. The pruning process. The basic idea of two pruning methods is similar, both of them use the idea of pre-pruning, which means the essence of pruning is judge whether it's worth to cut the brunch by comparing the loss function between before and after pruning. The pruning algorithm in CART is more advanced since the parameter \(\alpha\) is not a fixed number, and the pruning is happened in the local area (actually, the pruning in ID3 can also be improved to cut in a local area cause each time we just cut one brunch in the tree, which means the difference of loss function in that local area has the same value with that in the entire tree). CART pruning algorithm uses a series \(\alpha\) to find out the optimal tree instead of using a fixed value. All the codes in this atricle are collected on my github: Decision Tree References 统计学习方法 Regression Tree 回归树]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Decision Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Regularization in Machine Learnig]]></title>
    <url>%2F2019%2F04%2F03%2FRegularization-in-Machine-Learnig%2F</url>
    <content type="text"><![CDATA[Regularization in Machine Learning About Regularization The model will become overfitting when it is trying too hard to capture the outliers in the training dataset and the accuracy will have a low accuarcy in the testing set. Regularization is one of the most efficient methods for avoiding overfitting, in the essence, this approach could penalise weights(coefficients) in the model by making some of them toward to zero. What is the problem? Assume that we have an empirical loss function R: \[R_{emp} = {1\over{N}}\sum_{i=1}^NL(f(x_i), y_i)\] and the model function f: \[f(x_i) = w_0x_0 + w_1x_1 + w_2x_2 + w_3x_3 + ... + w_nx_n\] We can see the polynomial f is so complicated if there is no zero or very less zero in metrix w (the set of weights), and the model is also complex, which means this model can just fit well in the training set, in other word, it has a poor generalization ability. Obviously, we do not need that many non-zero and too large weights since not every features is useful in the estimating. Regulariztion is the approach that can cope this trouble. Regularization function can be understood as the complxity of model (cause it is a function about weights), it can be the norm of the model parameter vector, and different choices have different constrains on the weights, so the effect is also different. Actually, both a large amount of weights and weights with large values can lead to a complex model. The derivative will have a large fluctuation if our model is trying to fit the outlier in a specific interval, and a large derivative means the weight will also have a large value, therefore, a complex model always have parameters with large values. In the essence of solving overfitting problem, reularization term reduces the complexity of model from controlling the number and the value of parameters, the term is a constraint for the parameters when we are trying to minimize the loss function. L-P Norm We can understand norm as distance, it represents the size of vectors in vector space and the size of changing in matrix space. L-P norm is a set of norms: \[Lp = \sqrt[p]{\sum_{i=1}^Nx_i^p}\] Norms change accroding to the values of p: The above picture shows how the changes of the points whose distance (norm) to the origin is 1 in the three dimensional space. L0 Norm Normally we use L0 norm to represent the number of non-zero elements in a vector. Therefore, minimize L0 norm meams we want some weights become to zero, so that some features will not use in estimating, we can deduce the complexity of model through using L0 norm, unfortunately, it is hard to explain and calculate L0 norm since we can not interpret the meaning of zero-sqrt, and optimization of L0 norm is a NP hard question, but do not worry, we can use L1 norm to subtitue, which is an optimal convex approximation of L0 norm. L1 Norm This is the defination of L1 norm: \[||x||_1 = \sum_i{|x_i|}\] It represents the sum of the absolute values of non-zero elements in vector x. Due to the natural nature of L1 norm, the solution to L1 norm optimization is a sparse solution, we can use L1 norm to achieve the sparse of features, so that some unuseful features will be dropped. L2 Norm The defination of L2 norm is: \[||x||_2 = \sqrt{\sum_ix_i^2}\] We can make the value of weights toward to zero by minimizing L2 norm, but it is just toward instead of reaching at zero, which is different from L0 norm and L1 norm. Although there are several differences among L0, L1 and L2 norm, the essence of them is same, we use them to weaken or even drop some features, so that we can get a simpler model with a better generization ability. How it works? It is easy to answer this question after konwing the concept of norm: we just need to optimize the L1 or L2 norm, it can penalise weights atuomaticlly. However, do not forget our true aim: fitting data by minimizing the loss function. Therefore, we need to minimize loss function and regularization term simultaneously, but it is still easy to do that, we can minimize the sum of them: \[min{[R_{emp} + \lambda{r(w)}]}\] That is: \[min[{1\over{N}}\sum_{i=1}^NL(f(x_i), y_i) + {\lambda\over{2}}{||w||_2^2}]\] A larger lambda can impel to chose a simpler model and a smaller lambda will get a more complex model. Why L1 is sparse and L2 is smooth? As we said, L1 norm can make weights change to zero and L2 norm let the parameters toward to zero, we call L1 norm is sparse and L2 norm is smooth. We can understand this from different aspects. Mathmatical Formula Firstly, we assume the structural loss function with L1 norm is: \[L1 = R + {\lambda\over{n}}\sum_i|w_i|\] So we can calculate the derivative of w: \[{\partial{L1}\over{\partial{w}}}={\partial{R}\over{\partial{w}}}+{\lambda\over{n}}sign(w)\] And then: \[w^{t+1} = w^t - \eta{\partial{L1}\over{\partial{w^t}}}\] \[w^{t+1}=w^t-\eta{\partial{R}\over{\partial{w^t}}}-\eta{\lambda\over{n}}sign(w^t)\] And sign function is defined as: \[sign(x) = \begin{cases} +1 &amp; x&gt;0 \\ -1 &amp; x&lt;0 \\ [-1,1] &amp; x=0 \end{cases}\] As for the structural risk function with L2 norm: \[L2 = R + {\lambda\over{2n}}\sum_iw_i^2\] And then: \[{\partial{L2}\over{\partial{w}}}={\partial{R}\over{\partial{w}}}+{\lambda\over{n}}w\] \[w^{t+1} = w^t - \eta{\partial{L2}\over{\partial{w^t}}}\] \[w^{t+1}=w^t-\eta{\partial{R}\over{\partial{w^t}}}-\eta{\lambda\over{n}}w^t\] \[w^{t+1}=(1-\eta{\lambda\over{n}})w^t-\eta{\partial{R}\over{\partial{w^t}}}\] So we can see that the difference between the two formulas: the parameter w in \(L1\) minus \(\eta{\lambda\over{n}}sign(w)\) which is a constant for each \(w\) (see the deifnation of \(sign(x)\)). However, in \(L2\) it minus \(\eta{\lambda\over{n}}w\), which means \(w\) will reduce in a specific proportion in each iterations, and the proportion is \(\eta{\lambda\over{n}}\). Therefore, in some extent, L1 norm can make the parameteres(\(w\)) reduce to zero since it minus a constant each time, and L2 norm makes the weights toward to zero because reducing with a specific proportion. This is also the reason why we can use L1 norm to do feature selection(automaticlly) and use L2 norm to make the parameters smaller, and we also call L2 norm as weight decay. In addition, L2 norm has a more quicker reduction rate than L1 norm when \(w\) is in the interval \([1, +\infty]\), and L1 norm has a faster decreasing rate when \(w\) is in \((0, 1)\). So L1 norm can make \(w\) reach at zero more easier and get more zero elements in the parameter vector. Geometric Space We can also understand this question from geometric space. For the above picture, we assume that the red line is our empirical risk function(R), the light blue circle is the graph of L2 norm and the deep blue one is L1 norm. As we said, L1 and L2 norms are a kind of constraint for the function R, therefore, the intersection is our best solution, we can see that L1 norm can more easier to make the solution reach at zero. The same situation can be found in other empirical loss function, such as squared error: I am going to introduce another interpretation in geometric space which I believe can help us to understand this question better. As the above graph shows, assume that the purple line is our empirical loss function (R), and the green point is the local minimum. Now, we add L2 norm to the function, so we can get \(R+\lambda x^2\): The minimun has changed to the yellow point, it can be seen that the optimum value has reduced, but is not zero. We can get the new function \(R+\lambda |x|\) with L1 norm: The optimum changed to zero (the pink line). Remember that the truth is L1 norm can get optimum solution as zero more easier than L2 norm, which means we can not make sure the best value must be zero with L1 norm and L2 norm can also get zero value solution in the specific situation. I am going to interpret this situation. Actually, whether the two norms can change the optimal solution (the parameter/weight) to zero is depend on the value of derivative of zero point (x=0) in the empirical loss function: the derivative of zero point can not change to zero so the optimal solution is also non-zero if the original function (R) has non-zero derivative in the point x=0, in other words, L2 norm can change the optimal value to zero if the derivative of \(R_{emp}\) is zero in x=0. In terms of L1 norm, x=0 can be the optimal solution (local minimum) if the regularization coefficient \(\lambda\) is larger than the value of \(|R_{emp}&#39;(0)|\) (since we need to guarantee the derivates of left side and right side of x=0 have the opposite sign): The derivative of left side: \[R_{emp}&#39;(0)-\lambda\] The derivative of right side: \[R_{emp}&#39;(0)+\lambda\] Therefore, if: \[\lambda \geq |R_{emp}&#39;(0)|\] Then we can guarantee x=0 is the local minimum. Probability Degree Some Papers Reference l1 相比于 l2 为什么容易获得稀疏解？ 机器学习算法系列（28）：L1、L2正则化 聊一聊L1和2正则化 L1,L2,L0区别，为什么可以防止过拟合 机器学习中的范数规则化之（一）L0、L1与L2范数 常用的范数求导 统计学习方法]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Regularization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROC and AUC]]></title>
    <url>%2F2019%2F04%2F01%2FROC-and-AUC%2F</url>
    <content type="text"><![CDATA[ROC &amp; AUC Confusion Matrix I am going to introduce the concept of Confusion Matrix before talking about the ROC as well as AUC since I think this will help us to understand them better. Confusion Matrix is a performance measurement for machine learning classification, which is a specific table layout. Let us undetstand TP, FP, FN and TN first. As the above picture show, we define them as: TP(True Positive): The samples which are positive and have been predicted as positive FP(False Positive): The samples which are negative but have been predicted as positive FN(False Negative): The samples which are positive but have been predicted as negative TN(True Nagetive): The samples which are negative and have been predicted as negative So we can calculate the Recall and Precision easily. Recall means out of all the positive classes, how much we predicted correctly: \[Recall = {TP\over{TP + FN}}\] Precision means out of all the classes, how much we predicted correctly: \[Precision = {TP\over{TP + FP}}\] And we can also use F-Score (F1 or F-Measure), which can measure recall and precision simultaneously. F-Score is the harmonic mean of recall and precision: \[F_1 = ({Recall^{-1}+Precision^{-1}\over{2}})^{-1} ={2*Recall*Precision\over{Recall + Precision}}\] \[F_\beta = (1+\beta^2)*{Precision*Recall\over{(\beta^2*Precision)+Recall}}\] Where β is the weight of F-Score, it will give more proportion to Precision when β &lt; 1 and Recall gets a higher proportion when β &gt; 1, β = 1 is a specific situation which Recall and Precision has the same weight. However, it is difficult to compare two models with low precision and high recall or high precision and low recall since their F-Score could be similar. Here we have another two names: Sensitivity and Specificity: \[Sensitivity = Recall = True Positive Rate (TPR)\] \[Specificity = 1 - False Positive Rate (FPR) = 1 - {FP\over{FP + TN}}\] We can try to understand these from conditional probability aspect. Assume that our predict vales is Y' and Y is the true vale, so that: \[Precision = P(Y=1|Y&#39;=1)\] \[Recall = Sensitivity = P(Y&#39;=1|Y=1)\] \[Specificity = P(Y&#39;=0|Y=0)\] It can be seen that Recall (Sensitivity) and Specificity do not be influenced by imbalanced data but Precision relies on the proportion of positive and negative samples. The Precision-Recall Curve What's the problem of accuracy? Accuracy is one of the most common evaluation methods in machine learning, but it is not always appropriate: assume we have 100 samples in the test set, and there are 99 negative samples and just 1 positive sample, so that the accuracy of my model is 99/100 = 99% if it predicts all samples as negative class. Obviously, it can not evaluate our model in this case. \[Accuracy = {TP + TN\over{TP+TN+FP+FN}}\] What is ROC? ROC(Receiver Operating Characteristics) curve is a kind of tool which we can use to check or visualize the performance of the multi-classification models. ROC is based on confusion matrix which use FPR as x-axis and TPR as y-axis. We go through all the thresholds and draw the ROC graph, so that each points in ROC represents the FPR and TRP value in a specific threshold. How to evaluate ROC? The ROC will not change even we modify the threshold, the x-axis, FPR value can be understand as how much we predicted negative samples as positive which should be lower, and the y-axis, TPR value is how much we predicted correctly in the positive samples which should be higher, therefore, the performance of a model is good with high TPR and low FPR, which reflects as a steep ROC curve (The curve should tend to upper left corner). In addition, as we said Recall (Sensitivity, TPR) and Specificity (1-FPR) do not be influenced by imbalanced, so ROC curve will also not influenced by imbalanced data: What is AUC? AUC (Area Under the Curve) is the area under the ROC curve, the diagonal represents random effect which value is 0.5, positive and negative samples occupy the same proportion is the data set in this specific situation. The best value of AUC is 1 but can not reach in the most situation, and the worst is 0.5 which means classify samples ramdomly. For example, AUC is 0.7 means there is 70% chance that model will be able to distinguish between positive class and negative class. Relation between TPR and FPR As we know FPR is 1 - specificity, so when we increase TPR, FPR also increases and vice versa. Achievement by Python 12345678910111213141516from sklearn import metricsfrom sklearn.metics import f1_scoreimport numpy as np# True lablesy_true = np.array([1, 1, 2, 2]) # Probability estimates of the positive classy_scores = np.array([0,1, 0.4, 0.35, 0.8])auc_score = metrics.roc_auc_score(y_true, y_scores)&gt;&gt;&gt;print(auc_score)0.75y_true = [0, 1, 2, 0, 1, 2]y_pred = [0, 2, 1, 0, 0, 1]&gt;&gt;&gt;print(f1_score(f1_score(y_true, y_pred, average='micro')))0.33... Reference Confusion matrix Wikipedia 精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？ Understanding AUC - ROC Curve]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Model Evaluation</tag>
      </tags>
  </entry>
</search>
