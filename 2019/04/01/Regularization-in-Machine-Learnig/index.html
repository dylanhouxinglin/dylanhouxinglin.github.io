<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Machine Learning,Regularization,">










<meta name="description" content="Regularization About Regularization The model will become overfitting when it is trying too hard to capture the outliers in the training dataset and the accuracy will have a low accuarcy in the testin">
<meta name="keywords" content="Machine Learning,Regularization">
<meta property="og:type" content="article">
<meta property="og:title" content="Regularization in Machine Learnig">
<meta property="og:url" content="http://yoursite.com/2019/04/01/Regularization-in-Machine-Learnig/index.html">
<meta property="og:site_name" content="Just For Fun">
<meta property="og:description" content="Regularization About Regularization The model will become overfitting when it is trying too hard to capture the outliers in the training dataset and the accuracy will have a low accuarcy in the testin">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/images/regularization/norm.jpg">
<meta property="og:image" content="http://yoursite.com/images/regularization/L1_5.jpg">
<meta property="og:image" content="http://yoursite.com/images/regularization/L1_4.jpg">
<meta property="og:image" content="http://yoursite.com/images/regularization/L1_1.jpg">
<meta property="og:image" content="http://yoursite.com/images/regularization/L1_2.jpg">
<meta property="og:image" content="http://yoursite.com/images/regularization/L1_3.jpg">
<meta property="og:updated_time" content="2019-04-03T10:15:16.369Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Regularization in Machine Learnig">
<meta name="twitter:description" content="Regularization About Regularization The model will become overfitting when it is trying too hard to capture the outliers in the training dataset and the accuracy will have a low accuarcy in the testin">
<meta name="twitter:image" content="http://yoursite.com/images/regularization/norm.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"right","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/04/01/Regularization-in-Machine-Learnig/">





  <title>Regularization in Machine Learnig | Just For Fun</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Just For Fun</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/01/Regularization-in-Machine-Learnig/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="dylan_houxinglin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Just For Fun">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Regularization in Machine Learnig</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-01T20:48:43+11:00">
                2019-04-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="regularization">Regularization</h1>
<h2 id="about-regularization">About Regularization</h2>
<p>The model will become overfitting when it is trying too hard to capture the outliers in the training dataset and the accuracy will have a low accuarcy in the testing set. Regularization is one of the most efficient methods for avoiding overfitting, in the essence, this approach could penalise weights(coefficients) in the model by making some of them toward to zero.</p>
<h2 id="what-is-the-problem">What is the problem?</h2>
<p>Assume that we have an empirical loss function R: <span class="math display">\[R_{emp} = {1\over{N}}\sum_{i=1}^NL(f(x_i), y_i)\]</span> and the model function f: <span class="math display">\[f(x_i) = w_0x_0 + w_1x_1 + w_2x_2 + w_3x_3 + ... + w_nx_n\]</span> We can see the polynomial f is so complicated if there is no zero or very less zero in metrix <strong><em>w</em></strong> (the set of weights), and the model is also complex, which means this model can just fit well in the training set, in other word, it has a poor generalization ability. Obviously, we do not need that many non-zero and too large weights since not every features is useful in the estimating. Regulariztion is the approach that can cope this trouble. Regularization function can be understood as the complxity of model (cause it is a function about weights), it can be the norm of the model parameter vector, and different choices have different constrains on the weights, so the effect is also different.</p>
<p>Actually, both a large amount of weights and weights with large values can lead to a complex model. The derivative will have a large fluctuation if our model is trying to fit the outlier in a specific interval, and a large derivative means the weight will also have a large value, therefore, a complex model always have parameters with large values. In the essence of solving overfitting problem, reularization term reduces the complexity of model from controlling the number and the value of parameters, the term is a constraint for the parameters when we are trying to minimize the loss function.</p>
<h2 id="l-p-norm">L-P Norm</h2>
<p>We can understand norm as distance, it represents the size of vectors in vector space and the size of changing in matrix space. L-P norm is a set of norms: <span class="math display">\[Lp = \sqrt[p]{\sum_{i=1}^Nx_i^p}\]</span> Norms change accroding to the values of p: <img src="/images/regularization/norm.jpg" alt="norm"> The above picture shows how the changes of the points whose distance (norm) to the origin is 1 in the three dimensional space.</p>
<h3 id="l0-norm">L0 Norm</h3>
<p>Normally we use L0 norm to represent the number of non-zero elements in a vector. Therefore, minimize L0 norm meams we want some weights become to zero, so that some features will not use in estimating, we can deduce the complexity of model through using L0 norm, unfortunately, it is hard to explain and calculate L0 norm since we can not interpret the meaning of zero-sqrt, and optimization of L0 norm is a NP hard question, but do not worry, we can use L1 norm to subtitue, which is an optimal convex approximation of L0 norm.</p>
<h3 id="l1-norm">L1 Norm</h3>
<p>This is the defination of L1 norm: <span class="math display">\[||x||_1 = \sum_i{|x_i|}\]</span> It represents the sum of the absolute values of non-zero elements in vector x. Due to the natural nature of L1 norm, the solution to L1 norm optimization is a sparse solution, we can use L1 norm to achieve the sparse of features, so that some unuseful features will be dropped.</p>
<h3 id="l2-norm">L2 Norm</h3>
<p>The defination of L2 norm is: <span class="math display">\[||x||_2 = \sqrt{\sum_ix_i^2}\]</span> We can make the value of weights toward to zero by minimizing L2 norm, but it is just toward instead of reaching at zero, which is different from L0 norm and L1 norm. Although there are several differences among L0, L1 and L2 norm, the essence of them is same, we use them to weaken or even drop some features, so that we can get a simpler model with a better generization ability.</p>
<h2 id="how-it-works">How it works?</h2>
<p>It is easy to answer this question after konwing the concept of norm: we just need to optimize the L1 or L2 norm, it can penalise weights atuomaticlly. However, do not forget our true aim: fitting data by minimizing the loss function. Therefore, we need to minimize loss function and regularization term simultaneously, but it is still easy to do that, we can minimize the sum of them: <span class="math display">\[min{[R_{emp} + \lambda{r(w)}]}\]</span> That is: <span class="math display">\[min[{1\over{N}}\sum_{i=1}^NL(f(x_i), y_i) + {\lambda\over{2}}{||w||_2^2}]\]</span> A larger lambda can impel to chose a simpler model and a smaller lambda will get a more complex model.</p>
<h2 id="why-l1-is-sparse-and-l2-is-smooth">Why L1 is sparse and L2 is smooth?</h2>
<p>As we said, L1 norm can make weights change to zero and L2 norm let the parameters toward to zero, we call L1 norm is sparse and L2 norm is smooth. We can understand this from different aspects.</p>
<h3 id="mathmatical-formula">Mathmatical Formula</h3>
<p>Firstly, we assume the structural loss function with L1 norm is: <span class="math display">\[L1 = R + {\lambda\over{n}}\sum_i|w_i|\]</span> So we can calculate the derivative of w: <span class="math display">\[{\partial{L1}\over{\partial{w}}}={\partial{R}\over{\partial{w}}}+{\lambda\over{n}}sign(w)\]</span> And then: <span class="math display">\[w^{t+1} = w^t - \eta{\partial{L1}\over{\partial{w^t}}}\]</span> <span class="math display">\[w^{t+1}=w^t-\eta{\partial{R}\over{\partial{w^t}}}-\eta{\lambda\over{n}}sign(w^t)\]</span> And sign function is defined as: <span class="math display">\[sign(x) = \begin{cases}
+1 &amp; x&gt;0 \\
-1 &amp; x&lt;0 \\
[-1,1] &amp; x=0
\end{cases}\]</span> As for the structural risk function with L2 norm: <span class="math display">\[L2 = R + {\lambda\over{2n}}\sum_iw_i^2\]</span> And then: <span class="math display">\[{\partial{L2}\over{\partial{w}}}={\partial{R}\over{\partial{w}}}+{\lambda\over{n}}w\]</span> <span class="math display">\[w^{t+1} = w^t - \eta{\partial{L2}\over{\partial{w^t}}}\]</span> <span class="math display">\[w^{t+1}=w^t-\eta{\partial{R}\over{\partial{w^t}}}-\eta{\lambda\over{n}}w^t\]</span> <span class="math display">\[w^{t+1}=(1-\eta{\lambda\over{n}})w^t-\eta{\partial{R}\over{\partial{w^t}}}\]</span></p>
<p>So we can see that the difference between the two formulas: the parameter w in <span class="math inline">\(L1\)</span> minus <span class="math inline">\(\eta{\lambda\over{n}}sign(w)\)</span> which is a constant for each <span class="math inline">\(w\)</span> (see the deifnation of <span class="math inline">\(sign(x)\)</span>). However, in <span class="math inline">\(L2\)</span> it minus <span class="math inline">\(\eta{\lambda\over{n}}w\)</span>, which means <span class="math inline">\(w\)</span> will reduce in a specific proportion in each iterations, and the proportion is <span class="math inline">\(\eta{\lambda\over{n}}\)</span>.</p>
<p>Therefore, in some extent, L1 norm can make the parameteres(<span class="math inline">\(w\)</span>) reduce to zero since it minus a constant each time, and L2 norm makes the weights toward to zero because reducing with a specific proportion. This is also the reason why we can use L1 norm to do feature selection(automaticlly) and use L2 norm to make the parameters smaller, and we also call L2 norm as weight decay.</p>
<p>In addition, L2 norm has a more quicker reduction rate than L1 norm when <span class="math inline">\(w\)</span> is in the interval <span class="math inline">\([1, +\infty]\)</span>, and L1 norm has a faster decreasing rate when <span class="math inline">\(w\)</span> is in <span class="math inline">\((0, 1)\)</span>. So L1 norm can make <span class="math inline">\(w\)</span> reach at zero more easier and get more zero elements in the parameter vector.</p>
<h3 id="geometric-space">Geometric Space</h3>
<p>We can also understand this question from geometric space. <img src="/images/regularization/L1_5.jpg"> For the above picture, we assume that the red line is our empirical risk function(R), the light blue circle is the graph of L2 norm and the deep blue one is L1 norm. As we said, L1 and L2 norms are a kind of constraint for the function R, therefore, the intersection is our best solution, we can see that L1 norm can more easier to make the solution reach at zero.</p>
<p>The same situation can be found in other empirical loss function, such as squared error: <img src="/images/regularization/L1_4.jpg"></p>
<p>I am going to introduce another interpretation in geometric space which I believe us to understand this question better. <img src="/images/regularization/L1_1.jpg"> As the above graph shows, assume that the pink line is our empirical loss function (R), and the green point is the local minimum. Now, we add L2 norm to the function, so we can get <span class="math inline">\(R+\lambda x^2\)</span>: <img src="/images/regularization/L1_2.jpg"> The minimun has changed to the yellow point, it can be seen that the optimum value has reduced, but is not zero. We can get the new function <span class="math inline">\(R+\lambda |x|\)</span> with L1 norm: <img src="/images/regularization/L1_3.jpg"> The optimum changed to zero (the purple line).</p>
<p>Remember that the truth is L1 norm can get optimum solution as zero more easier than L2 norm, which means we can not make sure the best value must be zero with L1 norm and L2 norm can also get zero value solution in the specific situation. I am going to interpret this situation.</p>
<p>Actually, whether the two norms can change the optimal solution (the parameter/weight) to zero is depend on the value of derivative of zero point (x=0) in the empirical loss function: the derivative of zero point can not change to zero so the optimal solution is also non-zero if the original function (R) has non-zero derivative in the point x=0, in other words, L2 norm can change the optimal value to zero if the derivative of <span class="math inline">\(R_{emp}\)</span> is zero in x=0.</p>
<p>In terms of L1 norm, x=0 can be the optimal solution (local minimum) if the regularization coefficient <span class="math inline">\(\lambda\)</span> is larger than the value of <span class="math inline">\(|R_{emp}&#39;(0)|\)</span> (since we need to guarantee the derivates of left side and right side of x=0 have the opposite sign): The derivative of left side: <span class="math display">\[R_{emp}&#39;(0)-\lambda\]</span> The derivative of right side: <span class="math display">\[R_{emp}&#39;(0)+\lambda\]</span> Therefore, if: <span class="math display">\[\lambda \geq |R_{emp}&#39;(0)|\]</span> Then we can guarantee x=0 is the local minimum.</p>
<h3 id="probability-degree">Probability Degree</h3>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.zhihu.com/question/37096933" target="_blank" rel="noopener">l1 相比于 l2 为什么容易获得稀疏解？</a></li>
<li><a href="https://plushunter.github.io/2017/07/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8828%EF%BC%89%EF%BC%9AL1%E3%80%81L2%E6%AD%A3%E5%88%99%E5%8C%96/" target="_blank" rel="noopener">机器学习算法系列（28）：L1、L2正则化</a></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
            <a href="/tags/Regularization/" rel="tag"># Regularization</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/01/ROC-and-AUC/" rel="prev" title="ROC and AUC">
                ROC and AUC <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container"></div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/head.png" alt="dylan_houxinglin">
            
              <p class="site-author-name" itemprop="name">dylan_houxinglin</p>
              <p class="site-description motion-element" itemprop="description">Monash University Master of Data Science</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/dylanhouxinglin" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="xhou0008@student.monash.edu" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/hou-xing-lin-72/activities" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-zhihu"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#regularization"><span class="nav-number">1.</span> <span class="nav-text">Regularization</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#about-regularization"><span class="nav-number">1.1.</span> <span class="nav-text">About Regularization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#what-is-the-problem"><span class="nav-number">1.2.</span> <span class="nav-text">What is the problem?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#l-p-norm"><span class="nav-number">1.3.</span> <span class="nav-text">L-P Norm</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#l0-norm"><span class="nav-number">1.3.1.</span> <span class="nav-text">L0 Norm</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#l1-norm"><span class="nav-number">1.3.2.</span> <span class="nav-text">L1 Norm</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#l2-norm"><span class="nav-number">1.3.3.</span> <span class="nav-text">L2 Norm</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#how-it-works"><span class="nav-number">1.4.</span> <span class="nav-text">How it works?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#why-l1-is-sparse-and-l2-is-smooth"><span class="nav-number">1.5.</span> <span class="nav-text">Why L1 is sparse and L2 is smooth?</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mathmatical-formula"><span class="nav-number">1.5.1.</span> <span class="nav-text">Mathmatical Formula</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#geometric-space"><span class="nav-number">1.5.2.</span> <span class="nav-text">Geometric Space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#probability-degree"><span class="nav-number">1.5.3.</span> <span class="nav-text">Probability Degree</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reference"><span class="nav-number">1.6.</span> <span class="nav-text">Reference</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">dylan_houxinglin</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '',
          clientSecret: '',
          repo: '',
          owner: '',
          admin: [''],
          id: location.pathname,
          distractionFreeMode: ''
        })
        gitalk.render('gitalk-container')           
       </script>




  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src>
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
